{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccf9e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77c5ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = gpd.read_parquet(\"data/samples.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af93637c",
   "metadata": {},
   "source": [
    "# Validation data sampling\n",
    "\n",
    "For validation we are mostly going to use the cluster ids. \n",
    "\n",
    "We will aim for a rough 90/10 split.\n",
    "\n",
    "For HRVPP we can't use cluster_ids since those are too large (entire S2 tile) -> the validation set wouldn't have the necessary variance\n",
    "\n",
    "For Windthrow we can try taking a single windthrow event as validation. This should make sure that the algorithm couldn't learn from timing of the event, or from specific spatial structure for each windthrow event. However taking only a single event would not provide good variance over other parameters of windthrow events (can't show performance for winter storms vs summer storms etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38095ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "['Evoland', 'HRVPP', 'Windthrow']\n",
       "Length: 3, dtype: string"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[\"dataset\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "679b607e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "Evoland      484\n",
       "HRVPP         14\n",
       "Windthrow     12\n",
       "Name: cluster_id, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.groupby(\"dataset\")[\"cluster_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdec744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evoland validation\n",
    "evoland_cluster_samples = (\n",
    "    samples.query(\"dataset=='Evoland'\")[\"cluster_id\"]\n",
    "    .drop_duplicates()\n",
    "    .sample(frac=0.1, random_state=42)\n",
    ")\n",
    "evoland_val_samples = samples.query(\n",
    "    \"dataset=='Evoland' & cluster_id in @evoland_cluster_samples\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a6d9e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hrvpp validation\n",
    "# we're just sampling randomly on sample-id\n",
    "hrvpp_val_samples = samples.query(\"dataset=='HRVPP'\").sample(frac=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4365d8bd",
   "metadata": {},
   "source": [
    "## Windthrow\n",
    "\n",
    "First let's find out what makes sense to sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "457dda1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.400000000000002"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 30% of samples:\n",
    "len(samples.query(\"dataset=='Windthrow'\")) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d51100ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster_id\n",
       "CH20170802    38\n",
       "PL20170817    36\n",
       "DE20180118    34\n",
       "LV20220807    32\n",
       "NO20211119    32\n",
       "SI20200205    27\n",
       "IT20181028    25\n",
       "DE20171110    25\n",
       "IT20181029    23\n",
       "SE20181028     9\n",
       "FR20200122     7\n",
       "AU20181028     6\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.query(\"dataset=='Windthrow'\")[\"cluster_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4723634",
   "metadata": {},
   "source": [
    "From this it seems like we could barely get away with sampling two events. It makes sense to sample a summer and a winter/autumn event.\n",
    "Let's for now pick Austria and Norway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f751b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_events = [\"NO20211119\", \"AU20181028\"]\n",
    "wt_val_samples = samples.query(\"cluster_id in @val_events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b45a3b",
   "metadata": {},
   "source": [
    "## Compile train and val id lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5693fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ids = sorted(\n",
    "    evoland_val_samples[\"sample_id\"].to_list()\n",
    "    + hrvpp_val_samples[\"sample_id\"].to_list()\n",
    "    + wt_val_samples[\"sample_id\"].to_list()\n",
    ")\n",
    "train_ids = sorted(list(set(samples[\"sample_id\"].to_list()) - set(val_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe353ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389.20000000000005"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples[\"sample_id\"].unique()) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d664aaec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6740a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/val_ids.json\", \"w\") as f:\n",
    "    json.dump(val_ids, f)\n",
    "with open(\"data/train_ids.json\", \"w\") as f:\n",
    "    json.dump(train_ids, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disturbance-agent-data (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
