{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7f69e5b",
   "metadata": {},
   "source": [
    "# Fill out missing chips\n",
    "\n",
    "The initial extended evoland chips were gotten from AWS Element84 S2 COGs. This dataset is missing a bunch of recently reprocessed sentinel 2 data from the beginning of the data availability.\n",
    "\n",
    "This notebook aims to fill in any gaps using data from the official CDSE repository. \n",
    "\n",
    "To do this we follow a few steps. \n",
    "\n",
    "1. Get all dates of the chips available already\n",
    "2. Cross-reference with CDSE stac catalog\n",
    "3. Use SH Processing API to query missing chips\n",
    "\n",
    "To find the best way to do this we need to find out approximate numbers of how many chips are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3c21f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jonas.Viehweger\\Documents\\Projects\\2025\\DISFOR\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import math\n",
    "import traceback\n",
    "\n",
    "from tqdm import tqdm\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from sentinelhub import (\n",
    "    geo_utils,\n",
    "    CRS,\n",
    "    BBox,\n",
    "    DataCollection,\n",
    "    MimeType,\n",
    "    MosaickingOrder,\n",
    "    SentinelHubRequest,\n",
    "    SHConfig,\n",
    "    SentinelHubCatalog,\n",
    "    SentinelHubDownloadClient,\n",
    ")\n",
    "from affine import Affine\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "824ef969",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = gpd.read_parquet(\"../data/samples.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6004e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SHConfig(\"default-profile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b78f54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalscript_body = \"\"\"\n",
    "AVAILABLE = new Set();\n",
    "NOT_AVAILABLE = new Set();\n",
    "TO_INCLUDE_SET = new Set(TO_INCLUDE);\n",
    "\n",
    "function setup() {\n",
    "    return {\n",
    "        input: [{\n",
    "            bands: [\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\",\"B08\",\"B8A\",\"B11\",\"B12\",\"SCL\"],\n",
    "            units: \"DN\"\n",
    "        }],\n",
    "        output: TO_INCLUDE.map(date => ({\n",
    "            id: date,\n",
    "            bands: 11,\n",
    "            sampleType: \"INT16\"\n",
    "        })),\n",
    "        mosaicking: \"ORBIT\"\n",
    "    };\n",
    "}\n",
    "\n",
    "function preProcessScenes(collections) {\n",
    "    collections.scenes.orbits = collections.scenes.orbits.filter(function(orbit) {\n",
    "        var orbitDateFrom = orbit.dateFrom.split(\"T\")[0];\n",
    "        var toGet = TO_INCLUDE_SET.has(orbitDateFrom);\n",
    "        if(toGet){\n",
    "          AVAILABLE.add(orbitDateFrom)\n",
    "        }\n",
    "        return toGet\n",
    "    });\n",
    "    return collections;\n",
    "}\n",
    "\n",
    "function updateOutputMetadata(scenes, inputMetadata, outputMetadata){\n",
    "  outputMetadata.userData = Array.from(AVAILABLE)\n",
    "}\n",
    "\n",
    "function evaluatePixel(samples) {\n",
    "    let dataOutputs = {};\n",
    "    let sampleIndex = 0;\n",
    "    \n",
    "    for(let date of TO_INCLUDE){\n",
    "        if(AVAILABLE.has(date) && sampleIndex < samples.length){\n",
    "            let sample = samples[sampleIndex];\n",
    "            dataOutputs[date] = [\n",
    "                sample.B02, sample.B03, sample.B04, sample.B05, sample.B06,\n",
    "                sample.B07, sample.B08, sample.B8A, sample.B11, sample.B12, sample.SCL\n",
    "            ];\n",
    "            sampleIndex++;\n",
    "        } else {\n",
    "            dataOutputs[date] = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];\n",
    "        }\n",
    "    }\n",
    "    return dataOutputs;\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bf7a219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample(sample, evalscript_body, config):\n",
    "    \"\"\"Process a single sample - designed to be run in parallel.\"\"\"\n",
    "    centroid = sample.geometry\n",
    "    crs = CRS.get_utm_from_wgs84(centroid.x, centroid.y)\n",
    "    x, y = geo_utils.transform_point((centroid.x, centroid.y), CRS.WGS84, crs)\n",
    "    x_round = math.floor(x / 10) * 10\n",
    "    y_round = math.ceil(y / 10) * 10\n",
    "    resolution = 10\n",
    "    size = 32\n",
    "    bounds = (\n",
    "        x_round - (size * resolution) // 2,\n",
    "        y_round - (size * resolution) // 2,\n",
    "        x_round + (size * resolution) // 2,\n",
    "        y_round + (size * resolution) // 2,\n",
    "    )\n",
    "\n",
    "    bbox = BBox(bounds, crs=crs)\n",
    "    time_interval = \"2015-01-01\", \"2025-01-01\"\n",
    "\n",
    "    catalog = SentinelHubCatalog(config=config)\n",
    "    search_iterator = catalog.search(\n",
    "        DataCollection.SENTINEL2_L2A,\n",
    "        bbox=bbox,\n",
    "        time=time_interval,\n",
    "        filter=\"eo:cloud_cover < 80\",\n",
    "        fields={\n",
    "            \"include\": [\"id\", \"properties.datetime\", \"properties.eo:cloud_cover\"],\n",
    "            \"exclude\": [],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    results = list(search_iterator)\n",
    "    available_timestamps = list(\n",
    "        set(item[\"properties\"][\"datetime\"][0:10] for item in results)\n",
    "    )\n",
    "\n",
    "    available_timestamps.sort()\n",
    "\n",
    "    list_of_requests = []\n",
    "    for year in range(15, 25):\n",
    "        year_ts = [ts for ts in available_timestamps if ts[2:4] == str(year)]\n",
    "        evalscript = (\n",
    "            \"//VERSION 3\\n\" + \"TO_INCLUDE = \" + json.dumps(year_ts) + evalscript_body\n",
    "        )\n",
    "\n",
    "        request_all_bands = SentinelHubRequest(\n",
    "            evalscript=evalscript,\n",
    "            input_data=[\n",
    "                SentinelHubRequest.input_data(\n",
    "                    data_collection=DataCollection.SENTINEL2_L2A.define_from(\n",
    "                        \"s2l2a\", service_url=config.sh_base_url\n",
    "                    ),\n",
    "                    time_interval=(f\"20{year}-01-01\", f\"20{year + 1}-01-01\"),\n",
    "                    mosaicking_order=MosaickingOrder.LEAST_RECENT,\n",
    "                )\n",
    "            ],\n",
    "            responses=[\n",
    "                SentinelHubRequest.output_response(output, MimeType.TIFF)\n",
    "                for output in year_ts\n",
    "            ]\n",
    "            + [SentinelHubRequest.output_response(\"userdata\", MimeType.JSON)],\n",
    "            bbox=bbox,\n",
    "            size=(size, size),\n",
    "            config=config,\n",
    "        )\n",
    "        list_of_requests.append(request_all_bands)\n",
    "\n",
    "    download_list = [request.download_list[0] for request in list_of_requests]\n",
    "    # download data with multiple threads\n",
    "    data = SentinelHubDownloadClient(config=config).download(\n",
    "        download_list, max_threads=5\n",
    "    )\n",
    "\n",
    "    out_path = Path(f\"../data/tiffs/{sample.sample_id}\")\n",
    "    out_path.mkdir(parents=True, exist_ok=True)\n",
    "    for all_bands_response in data:\n",
    "        to_save = list(all_bands_response[\"userdata.json\"].values())\n",
    "        profile = {\n",
    "            \"driver\": \"GTiff\",\n",
    "            \"dtype\": \"uint16\",\n",
    "            \"nodata\": 0.0,\n",
    "            \"width\": 32,\n",
    "            \"height\": 32,\n",
    "            \"count\": 11,\n",
    "            \"crs\": crs.epsg,\n",
    "            \"transform\": Affine(10.0, 0.0, bounds[0], 0.0, -10.0, bounds[3]),\n",
    "            \"blockxsize\": 512,\n",
    "            \"blockysize\": 512,\n",
    "            \"tiled\": True,\n",
    "            \"compress\": \"zstd\",\n",
    "            \"interleave\": \"pixel\",\n",
    "        }\n",
    "\n",
    "        for date in to_save:\n",
    "            filename = f\"{date}.tif\"\n",
    "            with rasterio.open(out_path / filename, \"w\", **profile) as dst:\n",
    "                dst.write(np.transpose(all_bands_response[filename], (2, 0, 1)))\n",
    "\n",
    "    return sample.sample_id, len(to_save), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e46354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_get = []\n",
    "for sample_id in samples.sample_id:\n",
    "    if not Path(f\"../data/tiffs/{sample_id}\").exists():\n",
    "        to_get.append(sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26a17e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3714, 3770, 3780, 3790]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91a71f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_get = [3536, 3565, 3738, 3743, 3773, 3787]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f51a3f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = samples.query(\"sample_id in @to_get\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54587e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:27, 27.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 3565 succeeded: 56 files written\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:32, 14.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 3773 succeeded: 69 files written\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:36,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 3536 succeeded: 68 files written\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:39,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 3787 succeeded: 86 files written\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:41,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 3738 succeeded: 64 files written\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:42,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 3743 succeeded: 73 files written\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Main execution with ThreadPoolExecutor\n",
    "max_workers = 10  # Adjust based on your system and API rate limits\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = {\n",
    "        executor.submit(\n",
    "            process_sample, sample, evalscript_body, config\n",
    "        ): sample.sample_id\n",
    "        for _, sample in samples.iterrows()\n",
    "    }\n",
    "\n",
    "    for future in tqdm(as_completed(futures)):\n",
    "        sample_id = futures[future]\n",
    "        try:\n",
    "            result_id, count, error = future.result()\n",
    "            if error:\n",
    "                print(f\"Sample {sample_id} failed: {error}\")\n",
    "            else:\n",
    "                print(f\"Sample {sample_id} succeeded: {count} files written\")\n",
    "        except Exception:\n",
    "            # Now this will catch real exceptions with full stack traces\n",
    "            print(f\"Sample {sample_id} failed with exception:\")\n",
    "            traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disfor (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
