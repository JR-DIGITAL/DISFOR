{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"DISFOR","text":"<p>DISFOR offers dense labelled satellite time-series data on forest disturbance timing and agents of disturbance.</p> <p>Below are some examples of image chips together with their labels.</p> <p></p> <p>This package offers data classes to easily use the labelled data in machine learning tasks.</p> <p>See the Usage section for a short overview of the provided data and how to use the included data loading utilities.</p>"},{"location":"reference/","title":"Reference","text":""},{"location":"reference/#disfor.data","title":"<code>data</code>","text":""},{"location":"reference/#disfor.data.GenericDataset","title":"<code>GenericDataset</code>","text":"<p>A generic class which serves to load, filter and pre-process the raw data.</p> <p>There are two classes which then bring the filtered and pre-processed data into formats which can be used with pytorch (<code>disfor.torch.DisturbanceDataset</code>) and sklearn style classifiers (<code>disfor.data.ForestDisturbanceData</code>) respectively.</p> <p>Parameters:</p> Name Type Description Default <code>data_folder</code> <code>str | None</code> <p>Path to root data folder containng pixel_data.parquet, labels.parquet and samples.parquet, if not specified, data will be fetched using <code>disfor.data_fetcher.DATA_GETTER</code></p> <code>None</code> <code>target_classes</code> <code>List[Literal[100, 110, 120, 121, 122, 123, 200, 210, 211, 212, 213, 220, 221, 222, 230, 231, 232, 240, 241, 242, 243, 244, 245]] | None</code> <p>Which classes should be included</p> <code>None</code> <code>class_mapping_overrides</code> <code>Dict[int, int] | None</code> <p>Map classes to other classes for example {221: 211, 222: 211} would map both of the salvage classes to clear cut. This remapping happens before filtering of <code>target_classes</code>. This means that the items of the dict need to be specified in target_classes, otherwise they will be filtered out.</p> <code>None</code> <code>confidence</code> <code>List[Literal['high', 'medium']] | None</code> <p>Filters dataset to only include logged confidence of label interpretation.</p> <code>None</code> <code>valid_scl_values</code> <code>List[Literal[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]] | None</code> <p>List of valid SCL values. Used to filter out cloudy or otherwise unusable observations</p> <code>None</code> <code>chip_size</code> <code>Literal[32, 16, 8, 4]</code> <p>Size of the image chip. Maximum of 32x32. Used in <code>min_clear_percentage_chip</code>.</p> <code>32</code> <code>min_clear_percentage_chip</code> <code>int | None</code> <p>Minimum percent (0-100) of pixels in the chip that has to be clear (SCL in 4,5,6) to be included.</p> <code>None</code> <code>months</code> <code>List[Literal[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]] | None</code> <p>List of months to include acquisitions from. January is 1, December is 12.</p> <code>None</code> <code>max_days_since_event</code> <code>int | dict | None</code> <p>Either an integer specifying the maximum duration in days to the start label. This can also be set separately for each target_class. For example if target_classes is [110, 211] (Mature Forest, Clear Cut) we can specify a maximum number of 90 days after a Clear Cut by passing a dictionary with {211: 90}</p> <code>None</code> <code>sample_datasets</code> <code>List[Literal[1, 2, 3]] | None</code> <p>Data from which sampling campaign should be included. Includes data from all by default (None)</p> <code>None</code> <code>max_samples_per_event</code> <code>int | None</code> <p>Maximum number of acquisitions to include per event. Can be used to reduce number of samples drawn from segments with long durations. For example to reduce the number of healthy acquistions</p> <code>None</code> <code>random_seed</code> <code>int | None</code> <p>Random seed used for reproducible subsampling operations</p> <code>None</code> <code>apply_downsampling</code> <code>bool</code> <p>Flag if downsampling sampling of the majority class should be used.</p> <code>False</code> <code>target_majority_samples</code> <code>int | None</code> <p>How many samples the majority class should have after balancing. If None, the majority class will be reduced to 2 times the samples of the second largest class, or 500, whichever is less.</p> <code>None</code> <code>omit_border</code> <code>bool</code> <p>Omit samples which have \"border\" in the comment. These are usually samples where the sample is a mixed pixel</p> <code>True</code> <code>omit_low_tcd</code> <code>bool</code> <p>Omit samples which have \"TCD\" in the comment. These are usually samples where the forest has a low tree cover density (for example olive plantations)</p> <code>True</code> <code>bands</code> <code>List[Literal['B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B11', 'B12', 'SCL']] | None</code> <p>Spectral bands to include</p> <code>None</code> <code>remove_outliers</code> <code>bool</code> <p>Flag if outliers should be removed. This is used to remove clouds or other data artifacts which were not masked through the SCL values.</p> <code>False</code> <code>outlier_method</code> <code>Literal['iqr', 'zscore', 'modified_zscore']</code> <p>Statistical method used to determine outliers. This statistical measure is calculated for each unique <code>(sample_id, label)</code> group.</p> <code>'iqr'</code> <code>outlier_threshold</code> <code>float</code> <p>Which threshold to apply, acquisitions greater than <code>(outlier_threshold*outlier_method)</code> will be removed.</p> <code>1.5</code> <code>outlier_columns</code> <code>List[Literal['B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B11', 'B12', 'SCL']] | None</code> <p>Which columns (bands) to search for outliers. If an outlier is detected in any of the bands it will be removed. Default is all bands which are defined in the parameter <code>bands</code></p> <code>None</code> <code>label_strategy</code> <code>Literal['LabelEncoder', 'LabelBinarizer', 'Hierarchical']</code> <p>How the values in <code>target_classes</code> should be encoded. LabelEncoder and LabelBinarizer correspond to the sklearn encoders. Hierarchical is a custom encoding implemented for the hierarchical classes. For more details see <code>disfor.utils.HierarchicalLabelEncoder</code></p> <code>'LabelEncoder'</code> <p>Attributes:</p> Name Type Description <code>pixel_data</code> <p>Polars dataframe containing filtered and pre-processed data.</p> Source code in <code>src/disfor/data.py</code> <pre><code>class GenericDataset:\n    \"\"\"\n    A generic class which serves to load, filter and pre-process the raw data.\n\n    There are two classes which then bring the filtered and pre-processed data into formats which\n    can be used with pytorch ([`disfor.torch.DisturbanceDataset`][]) and sklearn style classifiers ([`disfor.data.ForestDisturbanceData`][]) respectively.\n\n    Args:\n        data_folder: Path to root data folder containng pixel_data.parquet, labels.parquet and samples.parquet,\n            if not specified, data will be fetched using [`disfor.data_fetcher.DATA_GETTER`][]\n        target_classes: Which classes should be included\n        class_mapping_overrides: Map classes to other classes for example {221: 211, 222: 211} would map both of the salvage classes to clear cut.\n            This remapping happens before filtering of `target_classes`. This means that the items of the dict need to be specified in target_classes,\n            otherwise they will be filtered out.\n        confidence: Filters dataset to only include logged confidence of label interpretation.\n        valid_scl_values: List of valid SCL values. Used to filter out cloudy or otherwise unusable observations\n        chip_size: Size of the image chip. Maximum of 32x32. Used in `min_clear_percentage_chip`.\n        min_clear_percentage_chip: Minimum percent (0-100) of pixels in the chip that has to be clear (SCL in 4,5,6) to be included.\n        months: List of months to include acquisitions from. January is 1, December is 12.\n        max_days_since_event: Either an integer specifying the maximum duration in days to the start label. This can also be set separately for each target_class.\n            For example if target_classes is [110, 211] (Mature Forest, Clear Cut) we can specify a maximum number of 90 days after a Clear Cut by passing a dictionary\n            with {211: 90}\n        sample_datasets: Data from which sampling campaign should be included. Includes data from all by default (None)\n        max_samples_per_event: Maximum number of acquisitions to include per event. Can be used to reduce number of samples\n            drawn from segments with long durations. For example to reduce the number of healthy acquistions\n        random_seed: Random seed used for reproducible subsampling operations\n        apply_downsampling: Flag if downsampling sampling of the majority class should be used.\n        target_majority_samples: How many samples the majority class should have after balancing. If None, the majority class will be reduced\n            to 2 times the samples of the second largest class, or 500, whichever is less.\n        omit_border: Omit samples which have \"border\" in the comment. These are usually samples where the sample is a mixed pixel\n        omit_low_tcd: Omit samples which have \"TCD\" in the comment. These are usually samples where the forest has a low tree cover density (for example olive plantations)\n        bands: Spectral bands to include\n        remove_outliers: Flag if outliers should be removed. This is used to remove clouds or other data artifacts\n            which were not masked through the SCL values.\n        outlier_method: Statistical method used to determine outliers. This statistical measure is calculated for each unique\n            `(sample_id, label)` group.\n        outlier_threshold: Which threshold to apply, acquisitions greater than `(outlier_threshold*outlier_method)` will be removed.\n        outlier_columns: Which columns (bands) to search for outliers. If an outlier is detected in any of the bands\n            it will be removed. Default is all bands which are defined in the parameter `bands`\n        label_strategy: How the values in `target_classes` should be encoded. LabelEncoder and LabelBinarizer correspond to the sklearn encoders.\n            Hierarchical is a custom encoding implemented for the hierarchical classes. For more details see [`disfor.utils.HierarchicalLabelEncoder`][]\n\n    Attributes:\n        pixel_data: Polars dataframe containing filtered and pre-processed data.\n    \"\"\"\n\n    def __init__(\n        self,\n        #\n        data_folder: str | None = None,\n        # Class selection\n        target_classes: List[\n            Literal[\n                100,\n                110,\n                120,\n                121,\n                122,\n                123,\n                200,\n                210,\n                211,\n                212,\n                213,\n                220,\n                221,\n                222,\n                230,\n                231,\n                232,\n                240,\n                241,\n                242,\n                243,\n                244,\n                245,\n            ]\n        ]\n        | None = None,\n        class_mapping_overrides: Dict[int, int] | None = None,\n        label_strategy: Literal[\n            \"LabelEncoder\", \"LabelBinarizer\", \"Hierarchical\"\n        ] = \"LabelEncoder\",\n        # Filtering parameters\n        confidence: List[Literal[\"high\", \"medium\"]] | None = None,\n        # Cloud masking parameters\n        valid_scl_values: List[Literal[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]]\n        | None = None,\n        chip_size: Literal[32, 16, 8, 4] = 32,\n        min_clear_percentage_chip: int | None = None,\n        months: List[Literal[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]] | None = None,\n        max_days_since_event: int | dict | None = None,\n        sample_datasets: List[Literal[1,2,3]] | None = None,\n        # Sampling parameters\n        max_samples_per_event: int | None = None,\n        random_seed: int | None = None,\n        # Balanced sampling parameters\n        apply_downsampling: bool = False,\n        target_majority_samples: int | None = None,\n        # Quality filters\n        omit_low_tcd: bool = True,\n        omit_border: bool = True,\n        # Feature selection\n        bands: List[\n            Literal[\n                \"B02\",\n                \"B03\",\n                \"B04\",\n                \"B05\",\n                \"B06\",\n                \"B07\",\n                \"B08\",\n                \"B8A\",\n                \"B11\",\n                \"B12\",\n                \"SCL\",\n            ]\n        ]\n        | None = None,\n        # Outlier removal parameters\n        remove_outliers: bool = False,\n        outlier_method: Literal[\"iqr\", \"zscore\", \"modified_zscore\"] = \"iqr\",\n        outlier_threshold: float = 1.5,\n        outlier_columns: List[\n            Literal[\n                \"B02\",\n                \"B03\",\n                \"B04\",\n                \"B05\",\n                \"B06\",\n                \"B07\",\n                \"B08\",\n                \"B8A\",\n                \"B11\",\n                \"B12\",\n                \"SCL\",\n            ]\n        ]\n        | None = None,\n    ):\n        self.random_seed = random_seed\n        self.data_folder = data_folder\n        self._load_base_data()\n        all_bands = [\n            \"B02\",\n            \"B03\",\n            \"B04\",\n            \"B05\",\n            \"B06\",\n            \"B07\",\n            \"B08\",\n            \"B8A\",\n            \"B11\",\n            \"B12\",\n            \"SCL\",\n        ]\n        self.bands = bands or all_bands[:-1]\n        self.band_idxs = [all_bands.index(band) for band in self.bands]\n        self.target_classes = target_classes or list(CLASSES.keys())\n        self.valid_scl_values = valid_scl_values or [2, 4, 5, 6]\n        self.outlier_method = outlier_method\n        self.outlier_threshold = outlier_threshold\n        self.outlier_columns = outlier_columns\n        self.class_mapping_overrides = class_mapping_overrides or {}\n        self.chip_size = chip_size\n        self.label_strategy = label_strategy\n\n        # Filters for samples.parquet\n        samples_filters = [pl.lit(True)]\n        # TODO: sample_ids should be handled in the implementing classes\n        if confidence is not None:\n            samples_filters.append(pl.col.confidence.is_in(confidence))\n        if sample_datasets is not None:\n            samples_filters.append(pl.col.dataset.is_in(sample_datasets))\n        if omit_low_tcd:\n            samples_filters.append(~pl.col.comment.str.contains(\"TCD\"))\n        if omit_border:\n            samples_filters.append(~pl.col.comment.str.contains(\"border\"))\n\n        # Filters for labels.parquet\n        labels_filters = [pl.lit(True)]\n        if target_classes is not None:\n            labels_filters.append(pl.col(\"label\").is_in(self.target_classes))\n        else:\n            # This is done because there are some labels with value 999 (artifact) in the labels dataset\n            # TODO: Fix this directly in the dataset? i.e. exclude 999\n            labels_filters.append(pl.col(\"label\").is_in(CLASSES.keys()))\n\n        # Filters for pixel_data.parquet\n        pixel_data_filters = [pl.lit(True)]\n        if months is not None:\n            pixel_data_filters.append(pl.col(\"timestamps\").dt.month().is_in(months))\n        if self.valid_scl_values is not None:\n            pixel_data_filters.append(pl.col.SCL.is_in(self.valid_scl_values))\n        if min_clear_percentage_chip is not None:\n            pixel_data_filters.append(\n                pl.col(f\"percent_clear_{chip_size}x{chip_size}\")\n                &gt;= min_clear_percentage_chip\n            )\n        match max_days_since_event:\n            case dict():\n                max_duration_filters = []\n                for label, days in max_days_since_event.items():\n                    if days is None:\n                        continue\n                    max_duration_filters.append(\n                        (\n                            (pl.col(\"timestamps\") - pl.col(\"start\"))\n                            &gt; pl.duration(days=days)\n                        )\n                        &amp; (pl.col.label == label)\n                    )\n                pixel_data_filters.append(~pl.any_horizontal(max_duration_filters))\n            case int():\n                pixel_data_filters.append(\n                    (\n                        (pl.col(\"timestamps\") - pl.col(\"start\"))\n                        &gt; pl.duration(days=max_days_since_event)\n                    )\n                )\n\n        # Load and filter samples data\n        samples = pl.read_parquet(\n            self.base_data_paths[\"samples.parquet\"],\n            columns=[\"sample_id\", \"cluster_id\", \"comment\", \"dataset\", \"confidence\"],\n            use_pyarrow=True,\n        ).filter(samples_filters)\n\n        labels = (\n            pl.read_parquet(\n                self.base_data_paths[\"labels.parquet\"],\n                columns=[\"sample_id\", \"label\", \"start\"],\n            )\n            .join(samples, on=\"sample_id\", how=\"inner\")\n            .with_columns(\n                pl.col.label.replace_strict(\n                    self.class_mapping_overrides,\n                    return_dtype=pl.UInt16,\n                    default=pl.col.label,\n                ),\n            )\n            .filter(labels_filters)\n        )\n\n        # Load and filter pixel data\n        pixel_data = (\n            pl.read_parquet(\n                self.base_data_paths[\"pixel_data.parquet\"],\n                columns=set(\n                    [\n                        \"sample_id\",\n                        \"SCL\",\n                        \"timestamps\",\n                        \"label\",\n                        f\"percent_clear_{chip_size}x{chip_size}\",\n                    ]\n                    + self.bands\n                ),\n            )\n            .join(labels, on=[\"sample_id\", \"label\"], how=\"inner\")\n            .filter(pixel_data_filters)\n        )\n\n        # Outlier removal using statistical measures\n        if remove_outliers and len(pixel_data) &gt; 0:\n            pixel_data = self._remove_outliers(pixel_data)\n\n        # Apply sampling sub-sampling per event\n        if max_samples_per_event is not None and len(pixel_data) &gt; 0:\n            if random_seed is not None:\n                pl.set_random_seed(random_seed)\n            if max_samples_per_event &gt; 0:\n                pixel_data = pixel_data.filter(\n                    pl.int_range(pl.len()).over([\"sample_id\", \"label\"])\n                    &lt; max_samples_per_event\n                )\n\n        if apply_downsampling and len(pixel_data) &gt; 0:\n            pixel_data = self._apply_balanced_sampling(\n                pixel_data, target_majority_samples\n            )\n\n        match label_strategy:\n            case \"LabelEncoder\":\n                from sklearn.preprocessing import LabelEncoder\n\n                self.encoder = LabelEncoder()\n            case \"LabelBinarizer\":\n                from sklearn.preprocessing import LabelBinarizer\n\n                self.encoder = LabelBinarizer()\n            case \"Hierarchical\":\n                from disfor.utils import HierarchicalLabelEncoder\n\n                self.encoder = HierarchicalLabelEncoder()\n\n        self.encoder.fit(self.target_classes)  # ty:ignore[invalid-argument-type]\n\n        if len(pixel_data) &gt; 0:\n            pixel_data = (\n                pixel_data.with_columns(\n                    label_encoded=pl.Series(\n                        self.encoder.transform(pixel_data[\"label\"].to_list())\n                    )\n                )\n                .sort(\"dataset\", \"cluster_id\")\n                .with_columns(\n                    cluster_id_encoded=pl.struct(\"dataset\", \"cluster_id\").rank(\"dense\"),\n                )\n            )\n\n        self.pixel_data = pixel_data\n\n    def _load_base_data(self):\n        \"\"\"Load base data files\"\"\"\n        required_data = [\n            \"classes.json\",\n            \"train_ids.json\",\n            \"val_ids.json\",\n            \"labels.parquet\",\n            \"pixel_data.parquet\",\n            \"samples.parquet\",\n        ]\n        if self.data_folder is None:\n            self.base_data_paths = {\n                filename: DATA_GETTER.fetch(filename) for filename in required_data\n            }\n        else:\n            self.base_data_paths = {\n                filename: Path(self.data_folder) / filename\n                for filename in required_data\n            }\n\n        with open(self.base_data_paths[\"classes.json\"], \"r\") as f:\n            self._class_mapping = {int(k): v for k, v in json.load(f).items()}\n\n        with open(self.base_data_paths[\"train_ids.json\"], \"r\") as f:\n            self._train_ids = json.load(f)\n\n        with open(self.base_data_paths[\"val_ids.json\"], \"r\") as f:\n            self._val_ids = json.load(f)\n\n    def _apply_balanced_sampling(\n        self, df: pl.DataFrame, target_majority_samples: int | None = None\n    ) -&gt; pl.DataFrame:\n        \"\"\"Apply balanced sampling by downsampling the majority class\"\"\"\n        counts = df[\"label\"].value_counts(sort=True)[0]\n\n        # return, if there's only one (or no) classes\n        if len(counts) &lt; 2:\n            return df\n\n        # Find majority class\n        max_count = counts[\"count\"][0]\n        majority_class = counts[\"label\"][0]\n\n        # Determine target size for majority class,\n        # If no target is set, the second largest class*2 is the maximum, if lower than 500\n        if target_majority_samples is None:\n            second_largest = counts[\"count\"][1]\n            target_majority_samples = min(max_count, max(second_largest * 2, 500))\n\n        # Set random seed if specified\n        if self.random_seed is not None:\n            pl.set_random_seed(self.random_seed)\n\n        # Split and downsample\n        majority_mask = pl.col(\"label\") == majority_class\n        majority_samples = df.filter(majority_mask).sample(\n            n=min(target_majority_samples, max_count)\n        )\n        minority_samples = df.filter(~majority_mask)\n\n        return pl.concat([minority_samples, majority_samples])\n\n    def _remove_outliers(self, df: pl.DataFrame) -&gt; pl.DataFrame:\n        \"\"\"Calculate outlier mask using the configured method\"\"\"\n        outlier_cols = (\n            self.outlier_columns if self.outlier_columns is not None else self.bands\n        )\n\n        mask = [pl.lit(False)]\n\n        if self.outlier_method == \"iqr\":\n            for col in outlier_cols:\n                q1 = pl.col(col).quantile(0.25).over(\"sample_id\", \"label\")\n                q3 = pl.col(col).quantile(0.75).over(\"sample_id\", \"label\")\n                iqr = q3 - q1\n                lower_bound = q1 - self.outlier_threshold * iqr\n                upper_bound = q3 + self.outlier_threshold * iqr\n                mask.append((pl.col(col) &lt; lower_bound) | (pl.col(col) &gt; upper_bound))\n\n        elif self.outlier_method == \"zscore\":\n            for col in outlier_cols:\n                mean = pl.col(col).mean().over(\"sample_id\", \"label\")\n                std = pl.col(col).std().over(\"sample_id\", \"label\")\n                z_score = ((pl.col(col) - mean) / std).abs()\n                mask.append(z_score &gt; self.outlier_threshold)\n\n        elif self.outlier_method == \"modified_zscore\":\n            for col in outlier_cols:\n                median_val = pl.col(col).median().over(\"sample_id\", \"label\")\n                mad = (\n                    ((pl.col(col) - pl.col(col).median()).abs())\n                    .median()\n                    .over(\"sample_id\", \"label\")\n                )\n                modified_z = 0.6745 * (pl.col(col) - median_val).abs() / mad\n                mask.append(modified_z &gt; self.outlier_threshold)\n\n        else:\n            raise ValueError(f\"Unknown outlier method: {self.outlier_method}\")\n\n        return df.filter(~pl.any_horizontal(mask))\n</code></pre>"},{"location":"reference/#disfor.data.ForestDisturbanceData","title":"<code>ForestDisturbanceData</code>","text":"<p>               Bases: <code>GenericDataset</code></p> <p>Class providing data for sklearn style models</p> <p>For usage see the dataloaders usage page.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>Unpack[DatasetParams]</code> <p>keyword arguments being passed to disfor.data.GenericDataset</p> <code>{}</code> Source code in <code>src/disfor/data.py</code> <pre><code>class ForestDisturbanceData(GenericDataset):\n    \"\"\"Class providing data for sklearn style models\n\n    For usage see the [dataloaders usage page](../usage/dataloaders).\n\n    Args:\n        **kwargs: keyword arguments being passed to [disfor.data.GenericDataset][]\n    \"\"\"\n\n    def __init__(self, **kwargs: Unpack[DatasetParams]):\n        super().__init__(**kwargs)\n        train_df = self.pixel_data.filter(pl.col.sample_id.is_in(self._train_ids))\n        test_df = self.pixel_data.filter(pl.col.sample_id.is_in(self._val_ids))\n\n        # Train\n        self.X_train = train_df[self.bands].to_numpy(writable=True)\n        self.y_train = train_df[\"label_encoded\"].to_numpy(writable=True)\n        self.group_train = train_df[\"cluster_id_encoded\"].to_numpy(writable=True)\n        # Test\n        self.X_test = test_df[self.bands].to_numpy(writable=True)\n        self.y_test = test_df[\"label_encoded\"].to_numpy(writable=True)\n        self.group_test = test_df[\"cluster_id_encoded\"].to_numpy(writable=True)\n</code></pre>"},{"location":"reference/#disfor.torch","title":"<code>torch</code>","text":""},{"location":"reference/#disfor.torch.DisturbanceDataset","title":"<code>DisturbanceDataset</code>","text":"<p>               Bases: <code>GenericDataset</code>, <code>Dataset</code></p> <p>PyTorch Dataset that loads image chips from stored GeoTIFFs.</p> Source code in <code>src/disfor/torch.py</code> <pre><code>class DisturbanceDataset(GenericDataset, Dataset):\n    \"\"\"PyTorch Dataset that loads image chips from stored GeoTIFFs.\"\"\"\n\n    def __init__(\n        self, sample_ids: List[int] | None = None, **kwargs: Unpack[DatasetParams]\n    ):\n        \"\"\"\n        Args:\n            sample_ids: List of sample_ids that should be included. Used for example to subset train and test splits\n        \"\"\"\n        super().__init__(**kwargs)\n        if self.data_folder is None:\n            from disfor.data_fetcher import fetch_s2_chips\n\n            self.tiff_folder = fetch_s2_chips()\n        else:\n            self.tiff_folder = Path(self.data_folder) / \"tiffs\"\n        if sample_ids is not None:\n            self.pixel_data = self.pixel_data.filter(pl.col.sample_id.is_in(sample_ids))\n        samples = self.pixel_data.select(\n            \"label\",\n            path=pl.format(\n                \"{}/{}.tif\",\n                pl.col.sample_id,\n                pl.col.timestamps.dt.strftime(\"%Y-%m-%d\"),\n            ),\n        )\n\n        # Pre-compute paths, labels, and chip indices to avoid string ops in __getitem__\n        tiff_half_size = 32 // 2\n        self.chip_range = (\n            tiff_half_size - self.chip_size // 2,\n            tiff_half_size + self.chip_size // 2,\n        )\n        self.file_paths = [self.tiff_folder / path for path in samples[\"path\"]]\n        self.labels = self.encoder.transform(samples[\"label\"].to_list())\n        match self.label_strategy:\n            case \"LabelEncoder\":\n                class_counts = np.unique_counts(self.labels).counts\n                self.class_weights = torch.from_numpy(\n                    class_counts.sum() / class_counts\n                ).float()\n            case \"LabelBinarizer\":\n                self.class_weights = torch.from_numpy(\n                    self.labels.sum() / self.labels.sum(axis=0)\n                ).float()\n            case \"Hierarchical\":\n                # don't have weights yet\n                self.class_weights = torch.ones(self.labels[0].shape)\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, index):\n        scale_factor = 10000\n        arr = (\n            tifffile.imread(self.file_paths[index])[\n                self.chip_range[0] : self.chip_range[1],\n                self.chip_range[0] : self.chip_range[1],\n                self.band_idxs,\n            ]\n            / scale_factor\n        )\n        return {\n            \"image\": torch.from_numpy(arr).permute(2, 0, 1).float(),\n            \"label\": torch.tensor(self.labels[index]),\n            \"path\": str(self.file_paths[index]),\n        }\n\n    def plot_chip(self, idx: int, ax: plt.Axes | None = None):\n        \"\"\"\n        Plot a true-color visualization of the chip.\n\n        Args:\n            idx: Index of the chip to plot\n            ax: Optional matplotlib axis. If None, creates new figure.\n        \"\"\"\n        sample = self[idx]\n        img = sample[\"image\"].numpy()\n        label_idx = sample[\"label\"].numpy()\n\n        class_id = self.encoder.inverse_transform(label_idx[np.newaxis, ...])[0]\n        label_name = CLASSES[class_id]\n\n        try:\n            r = self.bands.index(\"B04\")\n            g = self.bands.index(\"B03\")\n            b = self.bands.index(\"B02\")\n        except ValueError:\n            raise ValueError(\n                \"Bands B02, B03, B04 must be present for true-color visualization.\"\n            )\n\n        rgb = np.stack([img[r], img[g], img[b]], axis=-1)\n        gain = 5\n        rgb = np.clip(rgb * gain, 0, 1)\n\n        if ax is None:\n            plt.figure(figsize=(4, 4))\n            ax = plt.gca()\n\n        ax.imshow(rgb)\n        ax.set_title(f\"{class_id} - {label_name}\")\n        ax.axis(\"off\")\n\n        if ax is None:\n            plt.show()\n</code></pre>"},{"location":"reference/#disfor.torch.DisturbanceDataset.__init__","title":"<code>__init__(sample_ids=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>sample_ids</code> <code>List[int] | None</code> <p>List of sample_ids that should be included. Used for example to subset train and test splits</p> <code>None</code> Source code in <code>src/disfor/torch.py</code> <pre><code>def __init__(\n    self, sample_ids: List[int] | None = None, **kwargs: Unpack[DatasetParams]\n):\n    \"\"\"\n    Args:\n        sample_ids: List of sample_ids that should be included. Used for example to subset train and test splits\n    \"\"\"\n    super().__init__(**kwargs)\n    if self.data_folder is None:\n        from disfor.data_fetcher import fetch_s2_chips\n\n        self.tiff_folder = fetch_s2_chips()\n    else:\n        self.tiff_folder = Path(self.data_folder) / \"tiffs\"\n    if sample_ids is not None:\n        self.pixel_data = self.pixel_data.filter(pl.col.sample_id.is_in(sample_ids))\n    samples = self.pixel_data.select(\n        \"label\",\n        path=pl.format(\n            \"{}/{}.tif\",\n            pl.col.sample_id,\n            pl.col.timestamps.dt.strftime(\"%Y-%m-%d\"),\n        ),\n    )\n\n    # Pre-compute paths, labels, and chip indices to avoid string ops in __getitem__\n    tiff_half_size = 32 // 2\n    self.chip_range = (\n        tiff_half_size - self.chip_size // 2,\n        tiff_half_size + self.chip_size // 2,\n    )\n    self.file_paths = [self.tiff_folder / path for path in samples[\"path\"]]\n    self.labels = self.encoder.transform(samples[\"label\"].to_list())\n    match self.label_strategy:\n        case \"LabelEncoder\":\n            class_counts = np.unique_counts(self.labels).counts\n            self.class_weights = torch.from_numpy(\n                class_counts.sum() / class_counts\n            ).float()\n        case \"LabelBinarizer\":\n            self.class_weights = torch.from_numpy(\n                self.labels.sum() / self.labels.sum(axis=0)\n            ).float()\n        case \"Hierarchical\":\n            # don't have weights yet\n            self.class_weights = torch.ones(self.labels[0].shape)\n</code></pre>"},{"location":"reference/#disfor.torch.DisturbanceDataset.plot_chip","title":"<code>plot_chip(idx, ax=None)</code>","text":"<p>Plot a true-color visualization of the chip.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>Index of the chip to plot</p> required <code>ax</code> <code>Axes | None</code> <p>Optional matplotlib axis. If None, creates new figure.</p> <code>None</code> Source code in <code>src/disfor/torch.py</code> <pre><code>def plot_chip(self, idx: int, ax: plt.Axes | None = None):\n    \"\"\"\n    Plot a true-color visualization of the chip.\n\n    Args:\n        idx: Index of the chip to plot\n        ax: Optional matplotlib axis. If None, creates new figure.\n    \"\"\"\n    sample = self[idx]\n    img = sample[\"image\"].numpy()\n    label_idx = sample[\"label\"].numpy()\n\n    class_id = self.encoder.inverse_transform(label_idx[np.newaxis, ...])[0]\n    label_name = CLASSES[class_id]\n\n    try:\n        r = self.bands.index(\"B04\")\n        g = self.bands.index(\"B03\")\n        b = self.bands.index(\"B02\")\n    except ValueError:\n        raise ValueError(\n            \"Bands B02, B03, B04 must be present for true-color visualization.\"\n        )\n\n    rgb = np.stack([img[r], img[g], img[b]], axis=-1)\n    gain = 5\n    rgb = np.clip(rgb * gain, 0, 1)\n\n    if ax is None:\n        plt.figure(figsize=(4, 4))\n        ax = plt.gca()\n\n    ax.imshow(rgb)\n    ax.set_title(f\"{class_id} - {label_name}\")\n    ax.axis(\"off\")\n\n    if ax is None:\n        plt.show()\n</code></pre>"},{"location":"reference/#disfor.torch.DisturbanceDataModule","title":"<code>DisturbanceDataModule</code>","text":"<p>               Bases: <code>LightningDataModule</code></p> <p>Parameters:</p> Name Type Description Default <code>batch_size</code> <code>int</code> <p>Batch size for the dataloaders.</p> required <code>num_workers</code> <code>int</code> <p>Number of workers for data loading.</p> required <code>persist_workers</code> <code>bool</code> <p>If workers should persist between epochs</p> <code>True</code> <code>train_ids</code> <code>List[int]</code> <p>List of sample ids to include in training. If None, train test split from the dataset will be used</p> <code>None</code> <code>val_ids</code> <code>List[int]</code> <p>List of sample ids to include in validation. If None, train test split from the dataset will be used</p> <code>None</code> <code>**kwargs</code> <code>Unpack[DatasetParams]</code> <p>Passed on to DisturbanceDataset</p> <code>{}</code> Source code in <code>src/disfor/torch.py</code> <pre><code>class DisturbanceDataModule(L.LightningDataModule):\n    \"\"\"\n    Args:\n        batch_size (int): Batch size for the dataloaders.\n        num_workers (int): Number of workers for data loading.\n        persist_workers (bool): If workers should persist between epochs\n        train_ids (List[int]): List of sample ids to include in training. If None, train test split from the dataset will be used\n        val_ids (List[int]): List of sample ids to include in validation. If None, train test split from the dataset will be used\n        **kwargs: Passed on to DisturbanceDataset\n    \"\"\"\n\n    def __init__(\n        self,\n        batch_size: int,\n        num_workers: int,\n        persist_workers: bool = True,\n        data_folder: str | None = None,\n        train_ids: List[int] | None = None,\n        val_ids: List[int] | None = None,\n        **kwargs: Unpack[DatasetParams],\n    ):\n        super().__init__()\n        self.save_hyperparameters()\n        self.batch_size = batch_size\n        self.num_workers = num_workers\n        self.persist_workers = persist_workers\n        self.data_folder = data_folder\n        self.train_ids = train_ids\n        self.val_ids = val_ids\n        self.kwargs = kwargs\n\n        required_data = [\n            \"train_ids.json\",\n            \"val_ids.json\",\n        ]\n        if data_folder is None:\n            from disfor.data_fetcher import DATA_GETTER\n\n            base_data_paths = {\n                filename: DATA_GETTER.fetch(filename) for filename in required_data\n            }\n        else:\n            base_data_paths = {\n                filename: Path(data_folder) / filename for filename in required_data\n            }\n\n        if self.train_ids is None:\n            with open(base_data_paths[\"train_ids.json\"], \"r\") as f:\n                self.train_ids = json.load(f)\n        if self.val_ids is None:\n            with open(base_data_paths[\"val_ids.json\"], \"r\") as f:\n                self.val_ids = json.load(f)\n\n    def setup(self, stage=None) -&gt; None:\n        \"\"\"\n        Setup the datasets for training and validation.\n\n        Args:\n            stage (str): Stage of the training process ('fit', 'validate').\n        \"\"\"\n        if stage in {\"fit\", None}:\n            self.trn_ds = DisturbanceDataset(\n                sample_ids=self.train_ids, data_folder=self.data_folder, **self.kwargs\n            )\n            self.val_ds = DisturbanceDataset(\n                sample_ids=self.val_ids, data_folder=self.data_folder, **self.kwargs\n            )\n            self.class_weights = self.trn_ds.class_weights\n\n    def train_dataloader(self) -&gt; DataLoader:\n        \"\"\"\n        Returns the DataLoader for the training dataset.\n\n        Returns:\n            DataLoader: DataLoader for the training dataset.\n        \"\"\"\n        return DataLoader(\n            self.trn_ds,\n            batch_size=self.batch_size,\n            num_workers=self.num_workers,\n            shuffle=True,\n            pin_memory=True,\n            prefetch_factor=4 if self.num_workers &gt; 0 else None,\n            persistent_workers=self.persist_workers and self.num_workers &gt; 0,\n        )\n\n    def val_dataloader(self) -&gt; DataLoader:\n        \"\"\"\n        Returns the DataLoader for the validation dataset.\n\n        Returns:\n            DataLoader: DataLoader for the validation dataset.\n        \"\"\"\n        return DataLoader(\n            self.val_ds,\n            batch_size=self.batch_size * 2,\n            num_workers=self.num_workers,\n            prefetch_factor=4 if self.num_workers &gt; 0 else None,\n            persistent_workers=self.persist_workers and self.num_workers &gt; 0,\n        )\n</code></pre>"},{"location":"reference/#disfor.torch.DisturbanceDataModule.setup","title":"<code>setup(stage=None)</code>","text":"<p>Setup the datasets for training and validation.</p> <p>Parameters:</p> Name Type Description Default <code>stage</code> <code>str</code> <p>Stage of the training process ('fit', 'validate').</p> <code>None</code> Source code in <code>src/disfor/torch.py</code> <pre><code>def setup(self, stage=None) -&gt; None:\n    \"\"\"\n    Setup the datasets for training and validation.\n\n    Args:\n        stage (str): Stage of the training process ('fit', 'validate').\n    \"\"\"\n    if stage in {\"fit\", None}:\n        self.trn_ds = DisturbanceDataset(\n            sample_ids=self.train_ids, data_folder=self.data_folder, **self.kwargs\n        )\n        self.val_ds = DisturbanceDataset(\n            sample_ids=self.val_ids, data_folder=self.data_folder, **self.kwargs\n        )\n        self.class_weights = self.trn_ds.class_weights\n</code></pre>"},{"location":"reference/#disfor.torch.DisturbanceDataModule.train_dataloader","title":"<code>train_dataloader()</code>","text":"<p>Returns the DataLoader for the training dataset.</p> <p>Returns:</p> Name Type Description <code>DataLoader</code> <code>DataLoader</code> <p>DataLoader for the training dataset.</p> Source code in <code>src/disfor/torch.py</code> <pre><code>def train_dataloader(self) -&gt; DataLoader:\n    \"\"\"\n    Returns the DataLoader for the training dataset.\n\n    Returns:\n        DataLoader: DataLoader for the training dataset.\n    \"\"\"\n    return DataLoader(\n        self.trn_ds,\n        batch_size=self.batch_size,\n        num_workers=self.num_workers,\n        shuffle=True,\n        pin_memory=True,\n        prefetch_factor=4 if self.num_workers &gt; 0 else None,\n        persistent_workers=self.persist_workers and self.num_workers &gt; 0,\n    )\n</code></pre>"},{"location":"reference/#disfor.torch.DisturbanceDataModule.val_dataloader","title":"<code>val_dataloader()</code>","text":"<p>Returns the DataLoader for the validation dataset.</p> <p>Returns:</p> Name Type Description <code>DataLoader</code> <code>DataLoader</code> <p>DataLoader for the validation dataset.</p> Source code in <code>src/disfor/torch.py</code> <pre><code>def val_dataloader(self) -&gt; DataLoader:\n    \"\"\"\n    Returns the DataLoader for the validation dataset.\n\n    Returns:\n        DataLoader: DataLoader for the validation dataset.\n    \"\"\"\n    return DataLoader(\n        self.val_ds,\n        batch_size=self.batch_size * 2,\n        num_workers=self.num_workers,\n        prefetch_factor=4 if self.num_workers &gt; 0 else None,\n        persistent_workers=self.persist_workers and self.num_workers &gt; 0,\n    )\n</code></pre>"},{"location":"reference/#disfor.utils","title":"<code>utils</code>","text":""},{"location":"reference/#disfor.utils.HierarchicalLabelEncoder","title":"<code>HierarchicalLabelEncoder</code>","text":"<p>Sklearn-style encoder for hierarchical multi-class labels with multi-hot encoding.</p> <p>Assumes a 3-level hierarchy where: - Level 1: First digit (e.g., 1xx, 2xx) - Level 2: First two digits (e.g., 11x, 12x, 21x) - Level 3: All three digits (e.g., 110, 111, 211)</p> Source code in <code>src/disfor/utils.py</code> <pre><code>class HierarchicalLabelEncoder:\n    \"\"\"\n    Sklearn-style encoder for hierarchical multi-class labels with multi-hot encoding.\n\n    Assumes a 3-level hierarchy where:\n    - Level 1: First digit (e.g., 1xx, 2xx)\n    - Level 2: First two digits (e.g., 11x, 12x, 21x)\n    - Level 3: All three digits (e.g., 110, 111, 211)\n    \"\"\"\n\n    def __init__(self):\n        self.level1_classes_ = []\n        self.level2_classes_ = []\n        self.level3_classes_ = []\n        self.is_fitted_ = False\n\n    def _extract_hierarchy(self, label: int) -&gt; Tuple[int, int, int]:\n        \"\"\"Extract the three hierarchy levels from a label.\"\"\"\n        level1 = label // 100\n        level2 = label // 10\n        level3 = label\n        return level1, level2, level3\n\n    def fit(self, y: List[int]) -&gt; \"HierarchicalLabelEncoder\":\n        \"\"\"\n        Fit the encoder by discovering all unique classes at each hierarchy level.\n\n        Parameters:\n        -----------\n        y : List[int]\n            List of integer class labels\n\n        Returns:\n        --------\n        self : HierarchicalLabelEncoder\n        \"\"\"\n        level1_set = set()\n        level2_set = set()\n        level3_set = set()\n\n        for label in y:\n            l1, l2, l3 = self._extract_hierarchy(label)\n            level1_set.add(l1)\n            level2_set.add(l2)\n            level3_set.add(l3)\n\n        # Sort to ensure consistent ordering\n        self.level1_classes_ = sorted(level1_set)\n        self.level2_classes_ = sorted(level2_set)\n        self.level3_classes_ = sorted(level3_set)\n\n        self.is_fitted_ = True\n        return self\n\n    def transform(self, y: List[int]) -&gt; np.ndarray:\n        \"\"\"\n        Transform labels to hierarchical multi-hot encoding.\n\n        Parameters:\n        -----------\n        y : List[int]\n            List of integer class labels\n\n        Returns:\n        --------\n        encoded : np.ndarray\n            Multi-hot encoded array of shape (n_samples, n_features)\n            where n_features = len(level1) + len(level2) + len(level3)\n        \"\"\"\n        if not self.is_fitted_:\n            raise ValueError(\n                \"Encoder must be fitted before transform. Call fit() first.\"\n            )\n\n        n_samples = len(y)\n        n_level1 = len(self.level1_classes_)\n        n_level2 = len(self.level2_classes_)\n        n_level3 = len(self.level3_classes_)\n        n_features = n_level1 + n_level2 + n_level3\n\n        # Create mapping dictionaries for faster lookup\n        level1_map = {cls: idx for idx, cls in enumerate(self.level1_classes_)}\n        level2_map = {cls: idx for idx, cls in enumerate(self.level2_classes_)}\n        level3_map = {cls: idx for idx, cls in enumerate(self.level3_classes_)}\n\n        # Initialize output array\n        encoded = np.zeros((n_samples, n_features), dtype=int)\n\n        for i, label in enumerate(y):\n            l1, l2, l3 = self._extract_hierarchy(label)\n\n            # Set corresponding bits to 1\n            if l1 in level1_map:\n                encoded[i, level1_map[l1]] = 1\n            if l2 in level2_map:\n                encoded[i, n_level1 + level2_map[l2]] = 1\n            if l3 in level3_map:\n                encoded[i, n_level1 + n_level2 + level3_map[l3]] = 1\n\n        return encoded\n\n    def fit_transform(self, y: List[int]) -&gt; np.ndarray:\n        \"\"\"\n        Fit the encoder and transform labels in one step.\n\n        Parameters:\n        -----------\n        y : List[int]\n            List of integer class labels\n\n        Returns:\n        --------\n        encoded : np.ndarray\n            Multi-hot encoded array\n        \"\"\"\n        return self.fit(y).transform(y)\n\n    def inverse_transform(self, encoded: np.ndarray) -&gt; List[int]:\n        \"\"\"\n        Transform multi-hot encoded labels back to original labels.\n\n        Parameters:\n        -----------\n        encoded : np.ndarray\n            Multi-hot encoded array of shape (n_samples, n_features)\n\n        Returns:\n        --------\n        labels : List[int]\n            List of integer class labels\n        \"\"\"\n        if not self.is_fitted_:\n            raise ValueError(\"Encoder must be fitted before inverse_transform.\")\n\n        n_level1 = len(self.level1_classes_)\n        n_level2 = len(self.level2_classes_)\n\n        labels = []\n        for row in encoded:\n            # Extract active indices for each level\n            level3_idx = np.where(row[n_level1 + n_level2 :] == 1)[0]\n\n            if len(level3_idx) &gt; 0:\n                # Use the most specific level (level 3)\n                label = self.level3_classes_[level3_idx[0]]\n            else:\n                # Fallback to level 2 or level 1 if level 3 is not set\n                level2_idx = np.where(row[n_level1 : n_level1 + n_level2] == 1)[0]\n                if len(level2_idx) &gt; 0:\n                    label = self.level2_classes_[level2_idx[0]] * 10\n                else:\n                    level1_idx = np.where(row[:n_level1] == 1)[0]\n                    if len(level1_idx) &gt; 0:\n                        label = self.level1_classes_[level1_idx[0]] * 100\n                    else:\n                        label = 0  # Default if no class is set\n\n            labels.append(label)\n\n        return labels\n\n    def get_feature_names(self) -&gt; List[str]:\n        \"\"\"\n        Get feature names for the encoded output.\n\n        Returns:\n        --------\n        names : List[str]\n            List of feature names in format \"level1_X\", \"level2_XX\", \"level3_XXX\"\n        \"\"\"\n        if not self.is_fitted_:\n            raise ValueError(\"Encoder must be fitted before getting feature names.\")\n\n        names = []\n        names.extend([f\"level1_{cls}\" for cls in self.level1_classes_])\n        names.extend([f\"level2_{cls}\" for cls in self.level2_classes_])\n        names.extend([f\"level3_{cls}\" for cls in self.level3_classes_])\n\n        return names\n</code></pre>"},{"location":"reference/#disfor.utils.HierarchicalLabelEncoder.fit","title":"<code>fit(y)</code>","text":"<p>Fit the encoder by discovering all unique classes at each hierarchy level.</p>"},{"location":"reference/#disfor.utils.HierarchicalLabelEncoder.fit--parameters","title":"Parameters:","text":"<p>y : List[int]     List of integer class labels</p>"},{"location":"reference/#disfor.utils.HierarchicalLabelEncoder.fit--returns","title":"Returns:","text":"<p>self : HierarchicalLabelEncoder</p> Source code in <code>src/disfor/utils.py</code> <pre><code>def fit(self, y: List[int]) -&gt; \"HierarchicalLabelEncoder\":\n    \"\"\"\n    Fit the encoder by discovering all unique classes at each hierarchy level.\n\n    Parameters:\n    -----------\n    y : List[int]\n        List of integer class labels\n\n    Returns:\n    --------\n    self : HierarchicalLabelEncoder\n    \"\"\"\n    level1_set = set()\n    level2_set = set()\n    level3_set = set()\n\n    for label in y:\n        l1, l2, l3 = self._extract_hierarchy(label)\n        level1_set.add(l1)\n        level2_set.add(l2)\n        level3_set.add(l3)\n\n    # Sort to ensure consistent ordering\n    self.level1_classes_ = sorted(level1_set)\n    self.level2_classes_ = sorted(level2_set)\n    self.level3_classes_ = sorted(level3_set)\n\n    self.is_fitted_ = True\n    return self\n</code></pre>"},{"location":"reference/#disfor.utils.HierarchicalLabelEncoder.fit_transform","title":"<code>fit_transform(y)</code>","text":"<p>Fit the encoder and transform labels in one step.</p>"},{"location":"reference/#disfor.utils.HierarchicalLabelEncoder.fit_transform--parameters","title":"Parameters:","text":"<p>y : List[int]     List of integer class labels</p>"},{"location":"reference/#disfor.utils.HierarchicalLabelEncoder.fit_transform--returns","title":"Returns:","text":"<p>encoded : np.ndarray     Multi-hot encoded array</p> Source code in <code>src/disfor/utils.py</code> <pre><code>def fit_transform(self, y: List[int]) -&gt; np.ndarray:\n    \"\"\"\n    Fit the encoder and transform labels in one step.\n\n    Parameters:\n    -----------\n    y : List[int]\n        List of integer class labels\n\n    Returns:\n    --------\n    encoded : np.ndarray\n        Multi-hot encoded array\n    \"\"\"\n    return self.fit(y).transform(y)\n</code></pre>"},{"location":"reference/#disfor.utils.HierarchicalLabelEncoder.get_feature_names","title":"<code>get_feature_names()</code>","text":"<p>Get feature names for the encoded output.</p>"},{"location":"reference/#disfor.utils.HierarchicalLabelEncoder.get_feature_names--returns","title":"Returns:","text":"<p>names : List[str]     List of feature names in format \"level1_X\", \"level2_XX\", \"level3_XXX\"</p> Source code in <code>src/disfor/utils.py</code> <pre><code>def get_feature_names(self) -&gt; List[str]:\n    \"\"\"\n    Get feature names for the encoded output.\n\n    Returns:\n    --------\n    names : List[str]\n        List of feature names in format \"level1_X\", \"level2_XX\", \"level3_XXX\"\n    \"\"\"\n    if not self.is_fitted_:\n        raise ValueError(\"Encoder must be fitted before getting feature names.\")\n\n    names = []\n    names.extend([f\"level1_{cls}\" for cls in self.level1_classes_])\n    names.extend([f\"level2_{cls}\" for cls in self.level2_classes_])\n    names.extend([f\"level3_{cls}\" for cls in self.level3_classes_])\n\n    return names\n</code></pre>"},{"location":"reference/#disfor.utils.HierarchicalLabelEncoder.inverse_transform","title":"<code>inverse_transform(encoded)</code>","text":"<p>Transform multi-hot encoded labels back to original labels.</p>"},{"location":"reference/#disfor.utils.HierarchicalLabelEncoder.inverse_transform--parameters","title":"Parameters:","text":"<p>encoded : np.ndarray     Multi-hot encoded array of shape (n_samples, n_features)</p>"},{"location":"reference/#disfor.utils.HierarchicalLabelEncoder.inverse_transform--returns","title":"Returns:","text":"<p>labels : List[int]     List of integer class labels</p> Source code in <code>src/disfor/utils.py</code> <pre><code>def inverse_transform(self, encoded: np.ndarray) -&gt; List[int]:\n    \"\"\"\n    Transform multi-hot encoded labels back to original labels.\n\n    Parameters:\n    -----------\n    encoded : np.ndarray\n        Multi-hot encoded array of shape (n_samples, n_features)\n\n    Returns:\n    --------\n    labels : List[int]\n        List of integer class labels\n    \"\"\"\n    if not self.is_fitted_:\n        raise ValueError(\"Encoder must be fitted before inverse_transform.\")\n\n    n_level1 = len(self.level1_classes_)\n    n_level2 = len(self.level2_classes_)\n\n    labels = []\n    for row in encoded:\n        # Extract active indices for each level\n        level3_idx = np.where(row[n_level1 + n_level2 :] == 1)[0]\n\n        if len(level3_idx) &gt; 0:\n            # Use the most specific level (level 3)\n            label = self.level3_classes_[level3_idx[0]]\n        else:\n            # Fallback to level 2 or level 1 if level 3 is not set\n            level2_idx = np.where(row[n_level1 : n_level1 + n_level2] == 1)[0]\n            if len(level2_idx) &gt; 0:\n                label = self.level2_classes_[level2_idx[0]] * 10\n            else:\n                level1_idx = np.where(row[:n_level1] == 1)[0]\n                if len(level1_idx) &gt; 0:\n                    label = self.level1_classes_[level1_idx[0]] * 100\n                else:\n                    label = 0  # Default if no class is set\n\n        labels.append(label)\n\n    return labels\n</code></pre>"},{"location":"reference/#disfor.utils.HierarchicalLabelEncoder.transform","title":"<code>transform(y)</code>","text":"<p>Transform labels to hierarchical multi-hot encoding.</p>"},{"location":"reference/#disfor.utils.HierarchicalLabelEncoder.transform--parameters","title":"Parameters:","text":"<p>y : List[int]     List of integer class labels</p>"},{"location":"reference/#disfor.utils.HierarchicalLabelEncoder.transform--returns","title":"Returns:","text":"<p>encoded : np.ndarray     Multi-hot encoded array of shape (n_samples, n_features)     where n_features = len(level1) + len(level2) + len(level3)</p> Source code in <code>src/disfor/utils.py</code> <pre><code>def transform(self, y: List[int]) -&gt; np.ndarray:\n    \"\"\"\n    Transform labels to hierarchical multi-hot encoding.\n\n    Parameters:\n    -----------\n    y : List[int]\n        List of integer class labels\n\n    Returns:\n    --------\n    encoded : np.ndarray\n        Multi-hot encoded array of shape (n_samples, n_features)\n        where n_features = len(level1) + len(level2) + len(level3)\n    \"\"\"\n    if not self.is_fitted_:\n        raise ValueError(\n            \"Encoder must be fitted before transform. Call fit() first.\"\n        )\n\n    n_samples = len(y)\n    n_level1 = len(self.level1_classes_)\n    n_level2 = len(self.level2_classes_)\n    n_level3 = len(self.level3_classes_)\n    n_features = n_level1 + n_level2 + n_level3\n\n    # Create mapping dictionaries for faster lookup\n    level1_map = {cls: idx for idx, cls in enumerate(self.level1_classes_)}\n    level2_map = {cls: idx for idx, cls in enumerate(self.level2_classes_)}\n    level3_map = {cls: idx for idx, cls in enumerate(self.level3_classes_)}\n\n    # Initialize output array\n    encoded = np.zeros((n_samples, n_features), dtype=int)\n\n    for i, label in enumerate(y):\n        l1, l2, l3 = self._extract_hierarchy(label)\n\n        # Set corresponding bits to 1\n        if l1 in level1_map:\n            encoded[i, level1_map[l1]] = 1\n        if l2 in level2_map:\n            encoded[i, n_level1 + level2_map[l2]] = 1\n        if l3 in level3_map:\n            encoded[i, n_level1 + n_level2 + level3_map[l3]] = 1\n\n    return encoded\n</code></pre>"},{"location":"reference/#disfor.utils.generate_folds","title":"<code>generate_folds(n_folds, data_folder='data')</code>","text":"Source code in <code>src/disfor/utils.py</code> <pre><code>def generate_folds(n_folds: int, data_folder=\"data\"):\n    from sklearn.model_selection import StratifiedGroupKFold\n\n    groups = pl.read_parquet(\n        Path(data_folder) / \"samples.parquet\",\n        columns=[\"sample_id\", \"cluster_id\", \"comment\", \"dataset\", \"confidence\"],\n        use_pyarrow=True,\n    )\n    # sample_ids in HRVPP not highly correlated -&gt; use sample_id as group\n    # Evoland: Group by cluster_id\n    # Windthrow: Group by Wind Event\n    clusters = groups.with_columns(\n        cluster=pl.when(dataset=2)\n        .then(pl.col.sample_id.cast(pl.String))\n        .otherwise(pl.format(\"{}{}\", pl.col.dataset, pl.col.cluster_id))\n    )\n    samples_w_clusters = (\n        pl.read_parquet(Path(data_folder) / \"labels.parquet\")\n        .join(clusters.select(\"sample_id\", \"cluster\"), on=\"sample_id\")\n        .sort(\"cluster\")\n        .with_columns(\n            pl.col.label.cast(pl.Int16),\n            cluster_int=pl.col(\"cluster\").rle_id(),\n        )\n    )\n    sgkf = StratifiedGroupKFold(n_splits=n_folds)\n    splits = sgkf.split(\n        X=samples_w_clusters[\"label\"],\n        y=samples_w_clusters[\"label\"],\n        groups=samples_w_clusters[\"cluster_int\"],\n    )\n    folds = {}\n    sample_ids = samples_w_clusters[\"sample_id\"].to_numpy()\n    for i, (train_index, test_index) in enumerate(splits):\n        folds[i] = {}\n        folds[i][\"train_ids\"] = set(sample_ids[train_index].tolist())\n        folds[i][\"val_ids\"] = set(sample_ids[test_index].tolist())\n    return folds\n</code></pre>"},{"location":"reference/#disfor.data_fetcher","title":"<code>data_fetcher</code>","text":""},{"location":"reference/#disfor.data_fetcher.DATA_GETTER","title":"<code>DATA_GETTER = pooch.create(path=(pooch.os_cache('disfor')), base_url='https://huggingface.co/datasets/JR-DIGITAL/DISFOR/resolve/main/', version='0.1.0', version_dev='main', registry={'samples.parquet': '78200ae57211629d0c665177c5100bbe3dd3865818d1d08071ed63a2396997e7', 'labels.parquet': '13cf5d9ef367bd729654aae676c89f0315fc90af5ec36f9a7346465358759581', 'pixel_data.parquet': 'ba7fc3b6e98213c45d49440f4e6ccaff5e4e89d736b873cb62fe1a8946fe8608', 'train_ids.json': 'a661cfafd168d29b27ae2a46203668251d70148c78861de2e600a25d0dbf852e', 'val_ids.json': '429c27225be1b15fe675f0acf476eb7071afbc1ba8fde205c32896e3a7d44914', 'classes.json': 'c6377165ac17750f2fa91e2c859495c99d539a4166a085ef4d0d9d9adc8dae1a', 'disfor-0-499.tar.zst': 'fe062336c6db5106432983a24981fa3a7e7d854bc0699aeea85a7754f42e4c73', 'disfor-500-999.tar.zst': 'c20f4110402c5eeef912d5cf1d00410927102b0423775d54ba1fbfe134c563f9', 'disfor-1000-1499.tar.zst': '5e33c5bddc467060f603665866a795c665a94199813248376c9b21c2d5913f27', 'disfor-1500-1999.tar.zst': '0d92b7a7d93e7c539fa88399d9f7b8f0b6f280e064dca8d344f3af8f03f31de3', 'disfor-2000-2499.tar.zst': 'ac711fb765808ddddbab1f814770eab90473b4f5a3887867c3747b91fab8513c', 'disfor-2500-2999.tar.zst': '0a407d101d4af60fcf56a0c29be4265657515d61e77b427d0df11b7be6068e81', 'disfor-3000-3499.tar.zst': '51b9bfa9bc98464b241fde4626ed99516459cf9a68cc436b01a2dd73b4f4bda1', 'disfor-3500-3999.tar.zst': 'fa1ea1168c857bf4fc567d329a02db785584316468ad3401f1494887af8d37e3'})</code>  <code>module-attribute</code>","text":""},{"location":"usage/dataloaders/","title":"Data Loaders","text":"In\u00a0[1]: Copied! <pre>from disfor.data import ForestDisturbanceData\n</pre> from disfor.data import ForestDisturbanceData <p>The class <code>ForestDisturbanceData</code> provides arguments to filter the dataset and returns class properties which can be used for training of sklearn classifiers.</p> In\u00a0[2]: Copied! <pre>data = ForestDisturbanceData(\n    # If None, data gets dynamically downloaded and cached from Huggingface\n    data_folder=None,\n    # selecting healthy forest (110), clear cut (211) and bark beetle (231)\n    target_classes=[110, 211, 231],\n    # we remap salvage logging (221 and 222) to also be part of the clear cut class\n    # this happens before filtering the target_classes. This means, that all values in the\n    # mapping dict need to be in target_classes to be included\n    class_mapping_overrides={221: 211, 222: 211},\n    # subset to only include samples with high confidence\n    confidence=[\"high\"],\n    # only include acquisitions from \"leaf-on\" months\n    months=[5, 6, 7, 8, 9],\n    # including also dark pixels (2) as valid\n    valid_scl_values=[2, 4, 5, 6],\n    # only include acquisitions where the clear cut is recent (maximum of 90 days),\n    # for all other classes include everything\n    max_days_since_event={211: 90},\n    max_samples_per_event=5,\n    # omit samples which have low tcd in the comment\n    omit_low_tcd=True,\n    # omit samples which have border in the comment\n    omit_border=True,\n)\n</pre> data = ForestDisturbanceData(     # If None, data gets dynamically downloaded and cached from Huggingface     data_folder=None,     # selecting healthy forest (110), clear cut (211) and bark beetle (231)     target_classes=[110, 211, 231],     # we remap salvage logging (221 and 222) to also be part of the clear cut class     # this happens before filtering the target_classes. This means, that all values in the     # mapping dict need to be in target_classes to be included     class_mapping_overrides={221: 211, 222: 211},     # subset to only include samples with high confidence     confidence=[\"high\"],     # only include acquisitions from \"leaf-on\" months     months=[5, 6, 7, 8, 9],     # including also dark pixels (2) as valid     valid_scl_values=[2, 4, 5, 6],     # only include acquisitions where the clear cut is recent (maximum of 90 days),     # for all other classes include everything     max_days_since_event={211: 90},     max_samples_per_event=5,     # omit samples which have low tcd in the comment     omit_low_tcd=True,     # omit samples which have border in the comment     omit_border=True, ) <p>Once initialized, the class instance provides train and test data as numpy arrays.</p> In\u00a0[3]: Copied! <pre>print(data.y_train, data.X_train, data.y_test, data.X_test, sep=\"\\n\")\n</pre> print(data.y_train, data.X_train, data.y_test, data.X_test, sep=\"\\n\") <pre>[2 0 2 ... 0 0 0]\n[[1372 1478 1466 ... 3876 2721 1893]\n [ 166  310  228 ... 2732  826  367]\n [ 474  607  643 ... 1708 1812 1067]\n ...\n [ 148  230  132 ... 1515  890  462]\n [ 344  353  232 ... 1071  413  210]\n [ 241  300  178 ... 1446  691  312]]\n[0 0 0 ... 0 0 0]\n[[ 345  554  350 ... 2521 1182  581]\n [ 185  416  304 ... 2202 1315  682]\n [ 224  396  291 ... 2060 1204  593]\n ...\n [ 484  722  606 ... 3479 2669 1611]\n [ 246  304  291 ... 1335  885  488]\n [ 179  314  220 ... 2021 1105  575]]\n</pre> <p>It also provides the used label encoder, to go from the 0 to n-1 encoded labels back to the original labels.</p> In\u00a0[4]: Copied! <pre>data.encoder.inverse_transform(data.y_test)[:10]\n</pre> data.encoder.inverse_transform(data.y_test)[:10] Out[4]: <pre>array([110, 110, 110, 110, 110, 211, 211, 211, 211, 211])</pre> <p>Now, let's quickly train a Random Forest model and validate the output:</p> In\u00a0[5]: Copied! <pre>from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(oob_score=True)\nrf.fit(data.X_train, data.y_train)\n\nprint(rf.oob_score_)\n</pre> from sklearn.ensemble import RandomForestClassifier  rf = RandomForestClassifier(oob_score=True) rf.fit(data.X_train, data.y_train)  print(rf.oob_score_) <pre>0.9221816011340744\n</pre> <p>The out of box accuracy for the Random Forest model is 0.92. However let's use the held out set to get a better idea of the model accuracy. For this we apply the trained model on the held out predictors (<code>X_test</code>) and derive accuracy metrics from this.</p> In\u00a0[7]: Copied! <pre>from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n\ny_pred = rf.predict(data.X_test)\nprint(\n    classification_report(\n        data.y_test, y_pred, target_names=data.encoder.classes_.astype(str)\n    )\n)\n\ndisp = ConfusionMatrixDisplay.from_predictions(\n    data.y_test,\n    y_pred,\n    display_labels=[\"Undisturbed (110)\", \"Clear Cut (211)\", \"Bark Beetle (231)\"],\n    normalize=\"true\",\n)\n</pre> from sklearn.metrics import ConfusionMatrixDisplay, classification_report  y_pred = rf.predict(data.X_test) print(     classification_report(         data.y_test, y_pred, target_names=data.encoder.classes_.astype(str)     ) )  disp = ConfusionMatrixDisplay.from_predictions(     data.y_test,     y_pred,     display_labels=[\"Undisturbed (110)\", \"Clear Cut (211)\", \"Bark Beetle (231)\"],     normalize=\"true\", ) <pre>              precision    recall  f1-score   support\n\n         110       0.93      0.98      0.95      1208\n         211       0.83      0.69      0.76       147\n         231       0.74      0.46      0.57        85\n\n    accuracy                           0.92      1440\n   macro avg       0.83      0.71      0.76      1440\nweighted avg       0.91      0.92      0.91      1440\n\n</pre> <p>We can see that the undisturbed class is predicted well, however the other two classes are not predicted particularly well. Especially the precision is not great.</p> In\u00a0[8]: Copied! <pre>from disfor.torch import DisturbanceDataset\n\ntiff_dataset = DisturbanceDataset(\n    # If None, data gets dynamically downloaded and cached from Huggingface\n    data_folder=None,\n    # selecting healthy forest (110), clear cut (211) and bark beetle (231)\n    target_classes=[110, 211, 231],\n    # reduce the size of the chip, to include less context\n    chip_size=8,\n    # subset to only include samples with high confidence\n    confidence=[\"high\"],\n    # only include acquisitions from \"leaf-on\" months\n    months=[5, 6, 7, 8, 9],\n    # only include acquisitions where the clear cut is recent (maximum of 90 days),\n    # for all other classes include everything\n    max_days_since_event={211: 90},\n    max_samples_per_event=5,\n    # omit samples which have low tcd in the comment\n    omit_low_tcd=True,\n    # omit samples which have border in the comment\n    omit_border=True,\n)\n</pre> from disfor.torch import DisturbanceDataset  tiff_dataset = DisturbanceDataset(     # If None, data gets dynamically downloaded and cached from Huggingface     data_folder=None,     # selecting healthy forest (110), clear cut (211) and bark beetle (231)     target_classes=[110, 211, 231],     # reduce the size of the chip, to include less context     chip_size=8,     # subset to only include samples with high confidence     confidence=[\"high\"],     # only include acquisitions from \"leaf-on\" months     months=[5, 6, 7, 8, 9],     # only include acquisitions where the clear cut is recent (maximum of 90 days),     # for all other classes include everything     max_days_since_event={211: 90},     max_samples_per_event=5,     # omit samples which have low tcd in the comment     omit_low_tcd=True,     # omit samples which have border in the comment     omit_border=True, ) <p>The dataset returns a dictionary with the image, label and path of the image.</p> In\u00a0[9]: Copied! <pre>tiff_dataset[0]\n</pre> tiff_dataset[0] Out[9]: <pre>{'image': tensor([[[0.1408, 0.1472, 0.1444, 0.1362, 0.1326, 0.1460, 0.1572, 0.1476],\n          [0.1228, 0.1318, 0.1262, 0.1302, 0.1406, 0.1448, 0.1434, 0.1378],\n          [0.1142, 0.1202, 0.1210, 0.1338, 0.1434, 0.1454, 0.1332, 0.1230],\n          [0.1162, 0.1238, 0.1260, 0.1362, 0.1424, 0.1424, 0.1240, 0.1202],\n          [0.1098, 0.1238, 0.1224, 0.1266, 0.1372, 0.1384, 0.1258, 0.1250],\n          [0.0960, 0.1090, 0.1186, 0.1176, 0.1094, 0.1046, 0.1088, 0.1176],\n          [0.0958, 0.1108, 0.1238, 0.1176, 0.1024, 0.0890, 0.0924, 0.1086],\n          [0.1082, 0.1146, 0.1120, 0.1054, 0.0904, 0.0709, 0.0730, 0.0836]],\n \n         [[0.1684, 0.1698, 0.1746, 0.1824, 0.1826, 0.1832, 0.1828, 0.1726],\n          [0.1684, 0.1684, 0.1708, 0.1632, 0.1628, 0.1740, 0.1746, 0.1660],\n          [0.1592, 0.1572, 0.1536, 0.1470, 0.1480, 0.1590, 0.1616, 0.1598],\n          [0.1322, 0.1396, 0.1422, 0.1416, 0.1436, 0.1436, 0.1406, 0.1460],\n          [0.1278, 0.1310, 0.1370, 0.1430, 0.1478, 0.1400, 0.1318, 0.1272],\n          [0.1324, 0.1344, 0.1396, 0.1458, 0.1490, 0.1358, 0.1248, 0.1202],\n          [0.1264, 0.1310, 0.1344, 0.1438, 0.1466, 0.1360, 0.1320, 0.1288],\n          [0.1154, 0.1244, 0.1286, 0.1312, 0.1280, 0.1252, 0.1292, 0.1252]],\n \n         [[0.1638, 0.1664, 0.1684, 0.1590, 0.1544, 0.1598, 0.1638, 0.1522],\n          [0.1626, 0.1666, 0.1682, 0.1620, 0.1668, 0.1692, 0.1688, 0.1542],\n          [0.1538, 0.1584, 0.1648, 0.1652, 0.1688, 0.1698, 0.1682, 0.1594],\n          [0.1504, 0.1546, 0.1572, 0.1570, 0.1560, 0.1560, 0.1572, 0.1554],\n          [0.1450, 0.1468, 0.1476, 0.1450, 0.1466, 0.1484, 0.1492, 0.1466],\n          [0.1168, 0.1236, 0.1326, 0.1360, 0.1360, 0.1310, 0.1294, 0.1362],\n          [0.1138, 0.1150, 0.1222, 0.1332, 0.1332, 0.1236, 0.1226, 0.1258],\n          [0.1180, 0.1196, 0.1250, 0.1314, 0.1290, 0.1204, 0.1158, 0.1136]],\n \n         [[0.2167, 0.2167, 0.2206, 0.2206, 0.2234, 0.2234, 0.2181, 0.2181],\n          [0.2167, 0.2167, 0.2206, 0.2206, 0.2234, 0.2234, 0.2181, 0.2181],\n          [0.2099, 0.2099, 0.2130, 0.2130, 0.2136, 0.2136, 0.2098, 0.2098],\n          [0.2099, 0.2099, 0.2130, 0.2130, 0.2136, 0.2136, 0.2098, 0.2098],\n          [0.1991, 0.1991, 0.2031, 0.2031, 0.1940, 0.1940, 0.1934, 0.1934],\n          [0.1991, 0.1991, 0.2031, 0.2031, 0.1940, 0.1940, 0.1934, 0.1934],\n          [0.1770, 0.1770, 0.1851, 0.1851, 0.1806, 0.1806, 0.1704, 0.1704],\n          [0.1770, 0.1770, 0.1851, 0.1851, 0.1806, 0.1806, 0.1704, 0.1704]],\n \n         [[0.3383, 0.3383, 0.3566, 0.3566, 0.3715, 0.3715, 0.3575, 0.3575],\n          [0.3383, 0.3383, 0.3566, 0.3566, 0.3715, 0.3715, 0.3575, 0.3575],\n          [0.3285, 0.3285, 0.3254, 0.3254, 0.3237, 0.3237, 0.3206, 0.3206],\n          [0.3285, 0.3285, 0.3254, 0.3254, 0.3237, 0.3237, 0.3206, 0.3206],\n          [0.3381, 0.3381, 0.3251, 0.3251, 0.3119, 0.3119, 0.3021, 0.3021],\n          [0.3381, 0.3381, 0.3251, 0.3251, 0.3119, 0.3119, 0.3021, 0.3021],\n          [0.3141, 0.3141, 0.3234, 0.3234, 0.3078, 0.3078, 0.2860, 0.2860],\n          [0.3141, 0.3141, 0.3234, 0.3234, 0.3078, 0.3078, 0.2860, 0.2860]],\n \n         [[0.4004, 0.4004, 0.4049, 0.4049, 0.4202, 0.4202, 0.4088, 0.4088],\n          [0.4004, 0.4004, 0.4049, 0.4049, 0.4202, 0.4202, 0.4088, 0.4088],\n          [0.3760, 0.3760, 0.3705, 0.3705, 0.3706, 0.3706, 0.3580, 0.3580],\n          [0.3760, 0.3760, 0.3705, 0.3705, 0.3706, 0.3706, 0.3580, 0.3580],\n          [0.3892, 0.3892, 0.3775, 0.3775, 0.3558, 0.3558, 0.3413, 0.3413],\n          [0.3892, 0.3892, 0.3775, 0.3775, 0.3558, 0.3558, 0.3413, 0.3413],\n          [0.3669, 0.3669, 0.3834, 0.3834, 0.3680, 0.3680, 0.3399, 0.3399],\n          [0.3669, 0.3669, 0.3834, 0.3834, 0.3680, 0.3680, 0.3399, 0.3399]],\n \n         [[0.3992, 0.3924, 0.4176, 0.4188, 0.4308, 0.4520, 0.4400, 0.4236],\n          [0.3728, 0.3684, 0.3740, 0.3728, 0.3756, 0.3980, 0.4020, 0.4004],\n          [0.3472, 0.3404, 0.3392, 0.3520, 0.3612, 0.3624, 0.3616, 0.3648],\n          [0.3388, 0.3284, 0.3232, 0.3404, 0.3464, 0.3408, 0.3272, 0.3208],\n          [0.3720, 0.3588, 0.3452, 0.3400, 0.3460, 0.3400, 0.3140, 0.3090],\n          [0.3888, 0.3928, 0.3740, 0.3528, 0.3560, 0.3460, 0.3344, 0.3252],\n          [0.3400, 0.3740, 0.3920, 0.3792, 0.3516, 0.3364, 0.3300, 0.3164],\n          [0.3112, 0.3444, 0.3696, 0.3852, 0.3616, 0.3324, 0.3038, 0.3168]],\n \n         [[0.4433, 0.4433, 0.4423, 0.4423, 0.4529, 0.4529, 0.4426, 0.4426],\n          [0.4433, 0.4433, 0.4423, 0.4423, 0.4529, 0.4529, 0.4426, 0.4426],\n          [0.4045, 0.4045, 0.3963, 0.3963, 0.3989, 0.3989, 0.3912, 0.3912],\n          [0.4045, 0.4045, 0.3963, 0.3963, 0.3989, 0.3989, 0.3912, 0.3912],\n          [0.4209, 0.4209, 0.4074, 0.4074, 0.3876, 0.3876, 0.3643, 0.3643],\n          [0.4209, 0.4209, 0.4074, 0.4074, 0.3876, 0.3876, 0.3643, 0.3643],\n          [0.4015, 0.4015, 0.4155, 0.4155, 0.4011, 0.4011, 0.3665, 0.3665],\n          [0.4015, 0.4015, 0.4155, 0.4155, 0.4011, 0.4011, 0.3665, 0.3665]],\n \n         [[0.2837, 0.2837, 0.2820, 0.2820, 0.2778, 0.2778, 0.2670, 0.2670],\n          [0.2837, 0.2837, 0.2820, 0.2820, 0.2778, 0.2778, 0.2670, 0.2670],\n          [0.2752, 0.2752, 0.2796, 0.2796, 0.2772, 0.2772, 0.2721, 0.2721],\n          [0.2752, 0.2752, 0.2796, 0.2796, 0.2772, 0.2772, 0.2721, 0.2721],\n          [0.2670, 0.2670, 0.2734, 0.2734, 0.2721, 0.2721, 0.2655, 0.2655],\n          [0.2670, 0.2670, 0.2734, 0.2734, 0.2721, 0.2721, 0.2655, 0.2655],\n          [0.2529, 0.2529, 0.2622, 0.2622, 0.2597, 0.2597, 0.2516, 0.2516],\n          [0.2529, 0.2529, 0.2622, 0.2622, 0.2597, 0.2597, 0.2516, 0.2516]],\n \n         [[0.2124, 0.2124, 0.2043, 0.2043, 0.1960, 0.1960, 0.1898, 0.1898],\n          [0.2124, 0.2124, 0.2043, 0.2043, 0.1960, 0.1960, 0.1898, 0.1898],\n          [0.1954, 0.1954, 0.1980, 0.1980, 0.1933, 0.1933, 0.1876, 0.1876],\n          [0.1954, 0.1954, 0.1980, 0.1980, 0.1933, 0.1933, 0.1876, 0.1876],\n          [0.1883, 0.1883, 0.1940, 0.1940, 0.1893, 0.1893, 0.1824, 0.1824],\n          [0.1883, 0.1883, 0.1940, 0.1940, 0.1893, 0.1893, 0.1824, 0.1824],\n          [0.1834, 0.1834, 0.1887, 0.1887, 0.1852, 0.1852, 0.1756, 0.1756],\n          [0.1834, 0.1834, 0.1887, 0.1887, 0.1852, 0.1852, 0.1756, 0.1756]]]),\n 'label': tensor(2),\n 'path': '/home/jonas/.cache/disfor/0.1.0/tiffs/801/2020-06-10.tif'}</pre> <p>The image can also be plotted.</p> In\u00a0[10]: Copied! <pre>tiff_dataset.plot_chip(5001)\n</pre> tiff_dataset.plot_chip(5001) In\u00a0[11]: Copied! <pre>from disfor.torch import DisturbanceDataModule\n\ntiff_datamodule = DisturbanceDataModule(\n    batch_size=64,\n    num_workers=6,\n    # Keyword arguments are passed to TiffDataset\n    # selecting healthy forest (110), clear cut (211) and bark beetle (231)\n    target_classes=[110, 211, 231],\n    # reduce the size of the chip, to include less context\n    chip_size=8,\n    # subset to only include samples with high confidence\n    confidence=[\"high\"],\n    # only include acquisitions from \"leaf-on\" months\n    months=[5, 6, 7, 8, 9],\n    # only include acquisitions where the clear cut is recent (maximum of 90 days),\n    # for all other classes include everything\n    max_days_since_event={211: 90},\n    max_samples_per_event=5,\n    # omit samples which have low tcd in the comment\n    omit_low_tcd=True,\n    # omit samples which have border in the comment\n    omit_border=True,\n)\n</pre> from disfor.torch import DisturbanceDataModule  tiff_datamodule = DisturbanceDataModule(     batch_size=64,     num_workers=6,     # Keyword arguments are passed to TiffDataset     # selecting healthy forest (110), clear cut (211) and bark beetle (231)     target_classes=[110, 211, 231],     # reduce the size of the chip, to include less context     chip_size=8,     # subset to only include samples with high confidence     confidence=[\"high\"],     # only include acquisitions from \"leaf-on\" months     months=[5, 6, 7, 8, 9],     # only include acquisitions where the clear cut is recent (maximum of 90 days),     # for all other classes include everything     max_days_since_event={211: 90},     max_samples_per_event=5,     # omit samples which have low tcd in the comment     omit_low_tcd=True,     # omit samples which have border in the comment     omit_border=True, ) <p>To test this datamodule we are defining a very simple neural network to predict classes from the input images.</p> In\u00a0[12]: Copied! <pre>import torch\nimport torch.nn as nn\nimport lightning as L\n\n\nclass SimpleClassifier(L.LightningModule):\n    def __init__(self, num_classes=2, lr=1e-3):\n        super().__init__()\n        self.lr = lr\n\n        # Simple feedforward network\n        # Input: 10 channels * 8 * 8 = 640 features\n        self.model = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(10 * 8 * 8, 128),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(64, num_classes),\n        )\n\n        self.criterion = nn.CrossEntropyLoss()\n\n    def forward(self, x):\n        return self.model(x)\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch[\"image\"], batch[\"label\"]\n        logits = self(x)\n        loss = self.criterion(logits, y)\n        self.log(\"train_loss\", loss, prog_bar=True, batch_size=len(batch[\"label\"]))\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch[\"image\"], batch[\"label\"]\n        logits = self(x)\n        loss = self.criterion(logits, y)\n\n        # Calculate accuracy\n        preds = torch.argmax(logits, dim=1)\n        acc = (preds == y).float().mean()\n\n        self.log(\"val_loss\", loss, prog_bar=True, batch_size=len(batch[\"label\"]))\n        self.log(\"val_acc\", acc, prog_bar=True, batch_size=len(batch[\"label\"]))\n        return loss\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.lr)\n</pre> import torch import torch.nn as nn import lightning as L   class SimpleClassifier(L.LightningModule):     def __init__(self, num_classes=2, lr=1e-3):         super().__init__()         self.lr = lr          # Simple feedforward network         # Input: 10 channels * 8 * 8 = 640 features         self.model = nn.Sequential(             nn.Flatten(),             nn.Linear(10 * 8 * 8, 128),             nn.ReLU(),             nn.Dropout(0.2),             nn.Linear(128, 64),             nn.ReLU(),             nn.Dropout(0.2),             nn.Linear(64, num_classes),         )          self.criterion = nn.CrossEntropyLoss()      def forward(self, x):         return self.model(x)      def training_step(self, batch, batch_idx):         x, y = batch[\"image\"], batch[\"label\"]         logits = self(x)         loss = self.criterion(logits, y)         self.log(\"train_loss\", loss, prog_bar=True, batch_size=len(batch[\"label\"]))         return loss      def validation_step(self, batch, batch_idx):         x, y = batch[\"image\"], batch[\"label\"]         logits = self(x)         loss = self.criterion(logits, y)          # Calculate accuracy         preds = torch.argmax(logits, dim=1)         acc = (preds == y).float().mean()          self.log(\"val_loss\", loss, prog_bar=True, batch_size=len(batch[\"label\"]))         self.log(\"val_acc\", acc, prog_bar=True, batch_size=len(batch[\"label\"]))         return loss      def configure_optimizers(self):         return torch.optim.Adam(self.parameters(), lr=self.lr) <p>Finally we train the neural net using the data from our datamodule. As an example we are only going for 20 epochs.</p> In\u00a0[13]: Copied! <pre>model = SimpleClassifier(num_classes=3, lr=1e-3)\n\n# Train with your dataloader\ntrainer = L.Trainer(max_epochs=20)\ntrainer.fit(model, datamodule=tiff_datamodule)\n</pre> model = SimpleClassifier(num_classes=3, lr=1e-3)  # Train with your dataloader trainer = L.Trainer(max_epochs=20) trainer.fit(model, datamodule=tiff_datamodule) <pre>\ud83d\udca1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n</pre> <pre>GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n/home/jonas/Documents/Projects/2025/DISFOR/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n\n  | Name      | Type             | Params | Mode \n-------------------------------------------------------\n0 | model     | Sequential       | 90.5 K | train\n1 | criterion | CrossEntropyLoss | 0      | train\n-------------------------------------------------------\n90.5 K    Trainable params\n0         Non-trainable params\n90.5 K    Total params\n0.362     Total estimated model params size (MB)\n10        Modules in train mode\n0         Modules in eval mode\n</pre> <pre>                                                                           \r</pre> <pre>/home/jonas/Documents/Projects/2025/DISFOR/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n  warnings.warn(warn_msg)\n</pre> <pre>Epoch 19: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 210/210 [00:09&lt;00:00, 22.29it/s, v_num=9, train_loss=0.347, val_loss=0.221, val_acc=0.924] </pre> <pre>`Trainer.fit` stopped: `max_epochs=20` reached.\n</pre> <pre>Epoch 19: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 210/210 [00:09&lt;00:00, 22.27it/s, v_num=9, train_loss=0.347, val_loss=0.221, val_acc=0.924]\n</pre> <p>Now, let's look at the confusion matrix of the trained neural net:</p> In\u00a0[14]: Copied! <pre># After training, run validation and collect predictions\nmodel.eval()\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for batch in tiff_datamodule.val_dataloader():\n        x, y = batch[\"image\"], batch[\"label\"]\n        logits = model(x)\n        preds = torch.argmax(logits, dim=1)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(y.cpu().numpy())\n</pre> # After training, run validation and collect predictions model.eval() all_preds = [] all_labels = []  with torch.no_grad():     for batch in tiff_datamodule.val_dataloader():         x, y = batch[\"image\"], batch[\"label\"]         logits = model(x)         preds = torch.argmax(logits, dim=1)         all_preds.extend(preds.cpu().numpy())         all_labels.extend(y.cpu().numpy()) In\u00a0[15]: Copied! <pre>print(\n    classification_report(\n        all_labels,\n        all_preds,\n        target_names=[\"Healthy (110)\", \"Clear Cut (211)\", \"Bark Beetle (231)\"],\n    )\n)\n\ndisp = ConfusionMatrixDisplay.from_predictions(\n    all_labels,\n    all_preds,\n    display_labels=[\"Healthy (110)\", \"Clear Cut (211)\", \"Bark Beetle (231)\"],\n    normalize=\"true\",\n)\n</pre> print(     classification_report(         all_labels,         all_preds,         target_names=[\"Healthy (110)\", \"Clear Cut (211)\", \"Bark Beetle (231)\"],     ) )  disp = ConfusionMatrixDisplay.from_predictions(     all_labels,     all_preds,     display_labels=[\"Healthy (110)\", \"Clear Cut (211)\", \"Bark Beetle (231)\"],     normalize=\"true\", ) <pre>                   precision    recall  f1-score   support\n\n    Healthy (110)       0.93      0.99      0.96      1208\n  Clear Cut (211)       0.91      0.56      0.70       147\nBark Beetle (231)       0.80      0.67      0.73        85\n\n         accuracy                           0.92      1440\n        macro avg       0.88      0.74      0.80      1440\n     weighted avg       0.92      0.92      0.92      1440\n\n</pre> <p>After 20 epochs of training this very simple neural net, the model is outperforming the pixel based random forest model. Especially the class bark beetle is predicted more accurately.</p> <p>These models are just toy examples to show the integration of the provided datasets into training pipelines.</p>"},{"location":"usage/dataloaders/#data-loaders","title":"Data Loaders\u00b6","text":"<p>There are two dataloaders available to make working with the provided data more straightforward.</p> <ol> <li>Data loader providing spectral data and labels for a single pixel. Useful for scikit-learn classifiers</li> <li>Pytorch dataset and Pytorch Ligthning dataloader providing image chips together with labels</li> </ol> <p>In this notebook we show how these dataloaders can be used.</p>"},{"location":"usage/dataloaders/#pixel-dataloader","title":"Pixel dataloader\u00b6","text":""},{"location":"usage/dataloaders/#pytorch-dataloader","title":"Pytorch dataloader\u00b6","text":"<p>The pytorch dataloader is used for loading image chips. If it is the first time loading the data, it will be downloaded from Huggingface. For this at least 80GB of free disk space is necessary. After the first time loading, around 35GB of space will be used.</p> <p>The first data loading can take quite some time to download and extract the data.</p>"},{"location":"usage/dataloaders/#pytorch-lightning","title":"Pytorch Lightning\u00b6","text":"<p>For use with Pytorch Lightning, a Lightning datamodule is also available. This datamodule takes care of splitting the dataset into a training and validation set, so that the training progress can be monitored.</p> <p>The datamodule only takes a few extra parameters, like <code>batch_size</code>, <code>num_workers</code> and <code>persist_workers</code>. All of the reminaing parameters are passed as keyword arguments to <code>TiffDataset</code>.</p>"},{"location":"usage/dataset-overview/","title":"Dataset Overview","text":"In\u00a0[1]: Copied! <pre>import polars as pl\nimport geopandas as gpd\nimport numpy as np\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\nimport tifffile\nimport plotly.io as pio\n\nfrom disfor.data_fetcher import DATA_GETTER, fetch_s2_chips\n\npio.renderers.default = \"sphinx_gallery\"\n</pre> import polars as pl import geopandas as gpd import numpy as np import plotly.graph_objects as go from plotly.subplots import make_subplots import plotly.express as px import tifffile import plotly.io as pio  from disfor.data_fetcher import DATA_GETTER, fetch_s2_chips  pio.renderers.default = \"sphinx_gallery\" <p>DISFOR provides four datasets:</p> <ul> <li><code>samples.parquet</code>: Providing location and metadata of sampled points</li> <li><code>labels.parquet</code>: Providing labels for each sampled time-series</li> <li><code>pixel_data.parquet</code>: Providing Sentinel-2 band data for each acquistion in the time-series</li> <li>Sentinel-2 Chips: Image chip time-series for each sample</li> </ul> <p>These datasets are not available in this repository due to size, but available at huggingface for download. This package provides a data getter service (<code>disfor.data_fetcher.DATA_GETTER</code>), which helps to download all of the appropriate data.</p> <p>We will now go into the different datasets with more detail.</p> In\u00a0[2]: Copied! <pre>samples = gpd.read_parquet(DATA_GETTER.fetch(\"samples.parquet\"))\nsamples\n</pre> samples = gpd.read_parquet(DATA_GETTER.fetch(\"samples.parquet\")) samples Out[2]: sample_id original_sample_id interpreter dataset source source_description s2_tile cluster_id cluster_description comment confidence geometry 0 0 0 vij 1 EFFIS Evoland Project, EFFIS Source of Wildfire Poly... 30SUF 0.0 Damage polygons border, thinning, then clear cut high POINT (-4.12212 36.74179) 1 1 1 vij 1 EFFIS Evoland Project, EFFIS Source of Wildfire Poly... 30SUF 1.0 Damage polygons unclear progression, edge medium POINT (-4.12161 36.74231) 2 2 2 vij 1 EFFIS Evoland Project, EFFIS Source of Wildfire Poly... 30SUF 2.0 Damage polygons plantation high POINT (-4.1192 36.74203) 3 3 3 vij 1 EFFIS Evoland Project, EFFIS Source of Wildfire Poly... 30SUF 3.0 Damage polygons plantation high POINT (-4.12845 36.75831) 4 4 4 vij 1 EFFIS Evoland Project, EFFIS Source of Wildfire Poly... 30SUF 5.0 Damage polygons clear cut high POINT (-4.12816 36.75908) ... ... ... ... ... ... ... ... ... ... ... ... ... 3823 3818 16066 vij 3 FORWIND + Copernicus Emergency Service https://mapping.emergency.copernicus.eu/activa... &lt;NA&gt; SI20200205 Id of the Event, given as ISO2 + Date of storm &lt;NA&gt; high POINT (14.39175 46.2299) 3824 3819 16067 vij 3 FORWIND + Copernicus Emergency Service https://mapping.emergency.copernicus.eu/activa... &lt;NA&gt; SI20200205 Id of the Event, given as ISO2 + Date of storm unclear salvage high POINT (14.4004 46.2291) 3825 3820 16070 vij 3 FORWIND + Copernicus Emergency Service https://mapping.emergency.copernicus.eu/activa... &lt;NA&gt; SI20200205 Id of the Event, given as ISO2 + Date of storm &lt;NA&gt; high POINT (14.39046 46.24575) 3826 3821 16071 vij 3 FORWIND + Copernicus Emergency Service https://mapping.emergency.copernicus.eu/activa... &lt;NA&gt; SI20200205 Id of the Event, given as ISO2 + Date of storm unclear salvage high POINT (14.39247 46.2441) 3827 3822 16076 vij 3 FORWIND + Copernicus Emergency Service https://mapping.emergency.copernicus.eu/activa... &lt;NA&gt; SI20200205 Id of the Event, given as ISO2 + Date of storm &lt;NA&gt; high POINT (14.4381 46.25011) <p>3822 rows \u00d7 12 columns</p> <p>The dataset provides the following columns:</p> Column name Description sample_id Unique sample ID for each sample point original_sample_id Sample ID of the point in the original publication of the dataset interpreter Shorthand code for the interpreter who labelled this sample dataset Number of the original sampling campaign in which this point was labelled source The ancillary data source used to interpret the agent source_description A long text description of the used source. Link to the original data if available s2_tile If available, which Sentinel 2 Tile the sample intersects cluster_id Unique ID to group samples which are spatio-temporally autocorrelated cluster_description What type of cluster it is comment Free text comment about the interpretation of the sampled point confidence Confidence of sampling: high where both timing and agent are confident, medium were only the timing is confident geometry Coordinates of the sampled point. In CRS EPSG:4326 <p>For training of models this <code>samples</code> dataset can be used to subset the data. Some comments on how this dataset can be used to subset the data:</p> <ul> <li><p>Column <code>confidence</code>: For example if the agent is supposed to be modelled, the confidence can be set to only include samples with high confidence. However if a disturbance detection algorithm is supposed to be calibrated, then both high and medium confidence can be included.</p> </li> <li><p>Column <code>clusters</code>: If some data is supposed to be held out during training for validation purposes, the column <code>clusters</code> should be used to avoid high spatial autocorrelation between the train and test set. The <code>cluster_description</code> column specifies a unit for each value in the column <code>dataset</code> of how samples are clustered together. For example for HRVPP the samples are clustered by Sentinel 2 tiles. For Evoland the samples are clustered by disturbance patches (i.e. there might be multiple samples within the same disturbance patch) and for Windthrow the samples are clustered by windthrow event.</p> </li> <li><p>Column <code>comment</code>: The comments provide more context on the sample. They are free text but some of the more common comments are <code>border</code>, where the sample in on the border between two areas with different dynamics and thus exhibit high variability in the time-series, and <code>low TCD</code>, where usually mediterranean forests with low tree cover density are flagged.</p> </li> </ul> <p>Following is an interactive overview of where data is available.</p> In\u00a0[3]: Copied! <pre>samples.explore()\n</pre> samples.explore() Out[3]: Make this Notebook Trusted to load map: File -&gt; Trust Notebook In\u00a0[4]: Copied! <pre>labels = pl.read_parquet(DATA_GETTER.fetch(\"labels.parquet\"))\nlabels\n</pre> labels = pl.read_parquet(DATA_GETTER.fetch(\"labels.parquet\")) labels Out[4]: shape: (7_958, 8)original_sample_iddatasetlabeloriginal_labelstartendsample_idstart_next_labeli64u8u16strdatetime[ms, UTC]datetime[ms, UTC]u16datetime[ms, UTC]01110\"0\"2016-11-10 00:00:00 UTC2022-03-09 00:00:00 UTC02022-04-08 00:00:00 UTC01212\"6\"2022-04-08 00:00:00 UTC2022-04-08 23:59:59 UTC02024-04-02 00:00:00 UTC01211\"5\"2024-04-02 00:00:00 UTC2024-04-02 23:59:59 UTC0null11110\"0\"2016-11-10 00:00:00 UTC2023-05-03 00:00:00 UTC12023-06-22 00:00:00 UTC11211\"5\"2023-06-22 00:00:00 UTC2023-06-22 23:59:59 UTC1null\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026160713243\"7\"2020-03-11 00:00:00 UTC2020-03-11 23:59:59 UTC38212020-03-16 00:00:00 UTC160713120\"3\"2020-03-16 00:00:00 UTC2024-12-30 00:00:00 UTC3821null160763110\"0\"2017-08-04 00:00:00 UTC2020-01-21 00:00:00 UTC38222020-03-11 00:00:00 UTC160763243\"7\"2020-03-11 00:00:00 UTC2020-03-11 23:59:59 UTC38222020-06-29 00:00:00 UTC160763123\"4\"2020-06-29 00:00:00 UTC2024-12-30 00:00:00 UTC3822null <p>The following columns are available:</p> Column name Description sample_id Taken from sample table original_sample_id Taken from sample table dataset Taken from sample table label Interpreted class of the segment (see next table) original_label The label which was originally assigned and remapped to label start Start date of the segment end End date of the segment start_next_label Start date of the next label. Some labels are encoded as events (Clear Cuts for example) and are not immediately followed by another label, this column allows a full segmentation of the time-series. Null if it is the last label of the sample <p>The labelling campaign makes a distinction between events and segments. Temporal segments are periods of a distinct condition of the forest. This can include stable undisturbed forest, re-vegetation or bark beetle decline. Events on the other hand are singular changes of short duration. This includes most other disturbances like clear cutting, wildfire and windthrow events. In practice this distinction means that a single label is set for events, while two labels are set for segments, one for the start of the segment and one for the end.</p> <p>In this table, labels which are events have a start date in the morning of the day and an end date at midnight of the same date. To enable a full segmentation of the timeline, the <code>start_next_label</code> column is computed. This column provides the date when the next label starts, making a full segmentation of the time-series possible.</p> <p>The labels follow a hierarchical classification scheme:</p> Level 1 Level 2 Level 3 100 - Alive Vegetation 110 - Undisturbed Forest 120 - Revegetation 121 - With Trees (after clear cut) 122 - Canopy closing (after thinning/defoliation) 123 - Without Trees (shrubs and grasses, no reforestation visible) 200 - Disturbed 210 - Planned 211 - Clear Cut 212 - Thinning 213 - Forestry Mulching (Non Forest Vegetation Removal) 220 - Salvage 221 - After Biotic Disturbances 222 - After Abiotic Disturbances 230 - Biotic 231 - Bark Beetle 232 - Gypsy Moth (temporal segment of visible disturbance) 240 - Abiotic 241 - Drought 242 - Wildfire 243 - Wind 244 - Avalanche 245 - Flood <p>This allows for flexible labelling and classification.</p> In\u00a0[5]: Copied! <pre>pixel_data = pl.read_parquet(DATA_GETTER.fetch(\"pixel_data.parquet\"))\npixel_data\n</pre> pixel_data = pl.read_parquet(DATA_GETTER.fetch(\"pixel_data.parquet\")) pixel_data Out[5]: shape: (3_133_595, 19)B02B03B04B05B06B07B08B8AB11B12SCLsample_idtimestampspercent_clear_4x4percent_clear_8x8percent_clear_16x16percent_clear_32x32clearlabelu16u16u16u16u16u16u16u16u16u16u8u16dateu8u8u8u8boolu161035303431149365144554544467521111053402015-07-29100100100100truenull3320334031883580382538874240391234302714902015-08-080000falsenull032372113138214624474949131934894402015-08-18100100100100truenull3447566081416339641834084441720131018402015-08-28100100100100truenull346794539123233814128472443151715940402015-09-171001009284truenull\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026467558628101312891394140216381782127459992024-12-19100100100100true110290431608104413391576145417702160152459992024-12-21100100100100true110216364542103213111476130616482108158959992024-12-24100100100100true110352432596103312781549143817222290171159992024-12-26100100100100true110284415585104412721432131216432035162859992024-12-29100100100100true110 <p>The following columns are available:</p> Column name Datatype Description sample_id UINT16 Taken from sample table timestamp DATE UTC date of the S2 acquisition label UINT16 Interpreted class of the segment, see previous table clear BOOL True if the pixel is clear (SCL value any of 2,4,5,6) percent_clear_4x4 [8x8, 16x16, 32x32] UINT8 The percentage of clear pixels (SCL in 2,4,5,6) within a 4x4, 8x8, 16x16 or 32x32 pixel image chip B02, B03, B04, B05, B06, B07, B08, B8A, B11, B12 UINT16 DN value for the spectral band SCL UINT8 Sentinel 2 Scene Classification Value <p>Following is an example of a labelled time-series, together with Sentinel-2 image chips.</p> In\u00a0[6]: Copied! <pre>sample_id = 3733\n\nsample_data = (\n    pixel_data.filter(\n        pl.col.percent_clear_8x8 &gt; 0.9,\n        sample_id=sample_id,\n    )\n    .select(\n        \"timestamps\",\n        \"label\",\n        NDMI=(pl.col.B08.cast(pl.Int32) - pl.col.B11) / (pl.col.B08 + pl.col.B11),\n    )\n    .sort(\"timestamps\")\n)\n</pre> sample_id = 3733  sample_data = (     pixel_data.filter(         pl.col.percent_clear_8x8 &gt; 0.9,         sample_id=sample_id,     )     .select(         \"timestamps\",         \"label\",         NDMI=(pl.col.B08.cast(pl.Int32) - pl.col.B11) / (pl.col.B08 + pl.col.B11),     )     .sort(\"timestamps\") ) In\u00a0[7]: Copied! <pre>def get_rgb_array(sample_id, timestamp, data_path):\n    arr = (\n        tifffile.imread(f\"{data_path}/{sample_id}/{timestamp}.tif\")[\n            :,\n            :,\n            [2, 1, 0],\n        ]\n        / 10000\n    )\n    gain = 5\n    rgb = np.clip(arr * gain, 0, 1)\n    return rgb\n</pre> def get_rgb_array(sample_id, timestamp, data_path):     arr = (         tifffile.imread(f\"{data_path}/{sample_id}/{timestamp}.tif\")[             :,             :,             [2, 1, 0],         ]         / 10000     )     gain = 5     rgb = np.clip(arr * gain, 0, 1)     return rgb In\u00a0[8]: Copied! <pre>images = {}\nfor row in sample_data.iter_rows(named=True):\n    images[row[\"timestamps\"]] = get_rgb_array(\n        sample_id,\n        row[\"timestamps\"].strftime(\"%Y-%m-%d\"),\n        # If the S2 sample data, hasn't been downloaded before,\n        # this will take a while\n        fetch_s2_chips(),\n    )\n</pre> images = {} for row in sample_data.iter_rows(named=True):     images[row[\"timestamps\"]] = get_rgb_array(         sample_id,         row[\"timestamps\"].strftime(\"%Y-%m-%d\"),         # If the S2 sample data, hasn't been downloaded before,         # this will take a while         fetch_s2_chips(),     ) In\u00a0[9]: Copied! <pre># Ensure timestamps are datetime.date or datetime64\nsamples_data = sample_data.sort(\"timestamps\").to_pandas()\ntimestamps = [\n    timestamp.to_pydatetime().date()\n    for timestamp in samples_data[\"timestamps\"].to_list()\n]\nlabels_arr = samples_data[\"label\"].fillna(110).to_numpy(dtype=int)\nndmi = samples_data[\"NDMI\"].to_numpy()\n\n# --- Segment boundaries ---\nsegment_changes = np.concatenate(\n    [np.array([0]), np.where(labels_arr[:-1] != labels_arr[1:])[0] + 1]\n)\nn_chips = len(segment_changes)\n\n# --- Build subplot specs ---\nspecs = [[{\"type\": \"xy\"} for _ in range(n_chips)]] + [\n    [{\"colspan\": n_chips}, *[None] * (n_chips - 1)]\n]\n\nfig = make_subplots(\n    rows=2,\n    cols=n_chips,\n    specs=specs,\n    vertical_spacing=0,\n    horizontal_spacing=0,\n    row_heights=[0.3, 0.7],\n    subplot_titles=[\n        f\"label: {labels_arr[i]}&lt;br&gt;date: {timestamps[i].strftime('%Y-%m-%d')}\"\n        for i in segment_changes\n    ],\n)\n\n# --- Row 1: image chips ---\nfor j, i in enumerate(segment_changes):\n    try:\n        next_idx = segment_changes[j + 1] - 1\n    except IndexError:\n        next_idx = i + 5\n    ts = timestamps[min(i + 5, next_idx)]\n    if ts not in images:\n        continue  # skip if missing\n    img = np.clip(images[ts], 0, 1)\n    fig.add_trace(go.Image(z=(img * 255).astype(np.uint8)), row=1, col=j + 1)\n\n# --- Row 2: NDMI timeline with label-colored markers ---\nunique_labels = samples_data[\"label\"].dropna().unique().astype(int)\npalette = px.colors.qualitative.T10\ncolor_map = {lbl: palette[i % len(palette)] for i, lbl in enumerate(unique_labels)}\n\nfor lbl in unique_labels:\n    mask = samples_data[\"label\"] == lbl\n    fig.add_trace(\n        go.Scatter(\n            x=samples_data.loc[mask, \"timestamps\"],\n            y=samples_data.loc[mask, \"NDMI\"],\n            mode=\"lines+markers\",\n            name=f\"Label {lbl}\",\n            marker=dict(color=color_map[lbl], size=6, symbol=\"circle\"),\n            line=dict(color=color_map[lbl]),\n        ),\n        row=2,\n        col=1,\n    )\n\n# --- Layout tweaks ---\nfig.update_layout(\n    height=500,\n    width=650,\n    margin=dict(l=0, r=0, t=40, b=0),\n    title_font_size=12,\n    showlegend=True,\n    legend=dict(\n        orientation=\"h\",  # horizontal\n        yanchor=\"top\",\n        xanchor=\"center\",\n        x=0.5,\n        title_text=\"Labels\",\n    ),\n)\n\n# Remove axis labels only from image subplots (row 1)\nfor j in range(n_chips):\n    fig.update_xaxes(\n        showticklabels=False,\n        title_text=\"\",\n        showgrid=False,\n        zeroline=False,\n        row=1,\n        col=j + 1,\n    )\n    fig.update_yaxes(\n        showticklabels=False,\n        title_text=\"\",\n        showgrid=False,\n        zeroline=False,\n        row=1,\n        col=j + 1,\n    )\n\n# Keep axis labels for the timeline plot (row 2)\nfig.update_yaxes(title_text=\"NDMI\", row=2, col=1)\n\n# Make subplot titles smaller\nfig.update_annotations(font_size=10)\n\n# --- Save and show ---\nfig\n</pre> # Ensure timestamps are datetime.date or datetime64 samples_data = sample_data.sort(\"timestamps\").to_pandas() timestamps = [     timestamp.to_pydatetime().date()     for timestamp in samples_data[\"timestamps\"].to_list() ] labels_arr = samples_data[\"label\"].fillna(110).to_numpy(dtype=int) ndmi = samples_data[\"NDMI\"].to_numpy()  # --- Segment boundaries --- segment_changes = np.concatenate(     [np.array([0]), np.where(labels_arr[:-1] != labels_arr[1:])[0] + 1] ) n_chips = len(segment_changes)  # --- Build subplot specs --- specs = [[{\"type\": \"xy\"} for _ in range(n_chips)]] + [     [{\"colspan\": n_chips}, *[None] * (n_chips - 1)] ]  fig = make_subplots(     rows=2,     cols=n_chips,     specs=specs,     vertical_spacing=0,     horizontal_spacing=0,     row_heights=[0.3, 0.7],     subplot_titles=[         f\"label: {labels_arr[i]}date: {timestamps[i].strftime('%Y-%m-%d')}\"         for i in segment_changes     ], )  # --- Row 1: image chips --- for j, i in enumerate(segment_changes):     try:         next_idx = segment_changes[j + 1] - 1     except IndexError:         next_idx = i + 5     ts = timestamps[min(i + 5, next_idx)]     if ts not in images:         continue  # skip if missing     img = np.clip(images[ts], 0, 1)     fig.add_trace(go.Image(z=(img * 255).astype(np.uint8)), row=1, col=j + 1)  # --- Row 2: NDMI timeline with label-colored markers --- unique_labels = samples_data[\"label\"].dropna().unique().astype(int) palette = px.colors.qualitative.T10 color_map = {lbl: palette[i % len(palette)] for i, lbl in enumerate(unique_labels)}  for lbl in unique_labels:     mask = samples_data[\"label\"] == lbl     fig.add_trace(         go.Scatter(             x=samples_data.loc[mask, \"timestamps\"],             y=samples_data.loc[mask, \"NDMI\"],             mode=\"lines+markers\",             name=f\"Label {lbl}\",             marker=dict(color=color_map[lbl], size=6, symbol=\"circle\"),             line=dict(color=color_map[lbl]),         ),         row=2,         col=1,     )  # --- Layout tweaks --- fig.update_layout(     height=500,     width=650,     margin=dict(l=0, r=0, t=40, b=0),     title_font_size=12,     showlegend=True,     legend=dict(         orientation=\"h\",  # horizontal         yanchor=\"top\",         xanchor=\"center\",         x=0.5,         title_text=\"Labels\",     ), )  # Remove axis labels only from image subplots (row 1) for j in range(n_chips):     fig.update_xaxes(         showticklabels=False,         title_text=\"\",         showgrid=False,         zeroline=False,         row=1,         col=j + 1,     )     fig.update_yaxes(         showticklabels=False,         title_text=\"\",         showgrid=False,         zeroline=False,         row=1,         col=j + 1,     )  # Keep axis labels for the timeline plot (row 2) fig.update_yaxes(title_text=\"NDMI\", row=2, col=1)  # Make subplot titles smaller fig.update_annotations(font_size=10)  # --- Save and show --- fig <p>The time-series for this sample shows a time-series with a complex disturbance pattern. The sample is first thinned (212) in the beginning of 2023, then affected by windthrow (243), with subsequent salvage logging (222) and regreening (123).</p>"},{"location":"usage/dataset-overview/#dataset-overview","title":"Dataset Overview\u00b6","text":"<p>Here we will go through the provided data and explore the structure and metadata.</p> <p>For examples on how to use the data in machine and deep learning applications see the next section.</p>"},{"location":"usage/dataset-overview/#samples-dataset","title":"Samples dataset\u00b6","text":"<p>This is a geoparquet file which can be read with geopandas or QGIS.</p>"},{"location":"usage/dataset-overview/#labels-dataset","title":"Labels dataset\u00b6","text":"<p>The labels table provides labels for each data sample. These labels designate the start times of different events and segments within the sample time-series.</p>"},{"location":"usage/dataset-overview/#pixel-data","title":"Pixel data\u00b6","text":"<p>The <code>pixel_data.parquet</code> table provides Sentinel-2 data for the sample time-series to use in classification tasks. It also provides pre-computed columns for various chip sizes which measure the amount of \"clear\" pixels.</p>"}]}